"""

WhoBPyT Jansen-Rit model classes
---------------------------------

Authors: Zheng Wang, John Griffiths, Andrew Clappison, Hussain Ather, Sorenza Bastiaens, Parsa Oveisi, Kevin Kadak

Neural Mass Model fitting module for JR with connections from pyramidal to pyramidal, excitatory, and inhibitory populations for M/EEG

"""


"""
Importage
---------
"""

# Pytorch stuff

"""
Importage
"""

# PyTorch stuff
import torch
from torch.nn.parameter import Parameter
from torch.nn.parameter import Parameter as ptParameter
from torch.nn import ReLU as ptReLU
from torch.linalg import norm as ptnorm
from torch import (tensor as pttensor, float32 as ptfloat32, sum as ptsum, exp as ptexp, diag as ptdiag, 
                   transpose as pttranspose, zeros_like as ptzeros_like, int64 as ptint64, randn as ptrandn, 
                   matmul as ptmatmul, tanh as pttanh, matmul as ptmatmul, reshape as ptreshape, sqrt as ptsqrt,
                   ones as ptones, cat as ptcat)

import numpy as np
from numpy import ones,zeros

import os 
import json


data = {"username":"claires03","key":"ee39084a8974336d9fff7e1ced807e64"}
kaggle_path = os.path.join('/root/.config', 'kaggle')
if not os.path.exists(kaggle_path):
    os.makedirs(kaggle_path)
    print(f"Created directory: {kaggle_path}")
else:
    print(f"Directory already exists: {kaggle_path}")

kaggle_file = os.path.join('kaggle_path', '/kaggle.json')
with open(kaggle_file, 'w') as f:
    json.dump(data, f)

os.chmod(kaggle_file, 0o600)

import inspect

def method_arg_type_check(method_obj, exclude = []):
    """
    Takes the method object of a given function (e.g. RNNJANSEN) and checks that the passed arguments abide by their 
    expected data types.  If there is a discrepency, raises a ValueError.
    
    Optional argument: exclude
        List of strings containing argument names to exclude from the check (e.g. ['step_size', 'params']).  
        'self' is excluded automatically.
    """
    #This function is based on code generated by ChatGPT
    
    exclude.append('self')

    args_signature = inspect.signature(method_obj)
    expected_types = {param.name: param.annotation for param in args_signature.parameters.values() if param.name not in exclude} # Extract expected parameter types from the signature

    for arg_name, arg_type in expected_types.items(): # Iterate through each passed arguments' label and data type
        if arg_name in locals(): # Skip 'self' argument and check if argument is present
            if not isinstance(locals()[arg_name], arg_type): # Check if the passed arg's data type does not match its expected type
                passed_arg_type = type(locals()[arg_name]).__name__ # Passed data type
                expected_arg_type = arg_type.__name__ # Expected data type
                raise ValueError(f"{arg_name} should be of type {expected_arg_type}, but got type {passed_arg_type} instead.") # Halt if discrepancy

class par:
    '''
    Features of this class:
     - This class contains a global parameter value or array of values (one per node)
     - It can also contain associated priors (mean and variance)
     - It also has attributes for whether the parameter and/or priors should be fit during training
     - It has a method to return the parameter as numpy value
     - It has a method to set a random val using based on priors
     - It has functionality to represent val as log(val) so that during training val will be constrained to be positive

    Attributes
    ------------
    val : Tensor
        The parameter value (or an array of node specific parameter values)
    prior_mean : Tensor
        Prior mean of the data value
    prior_var_inv : Tensor
        Prior inverse of variance of the value
    
    fit_par: Bool
        Whether the parameter value should be set to as a PyTorch Parameter
    fit_hyper : Bool
        Whether the parameter prior mean and prior variance should be set as a PyTorch Parameter
    asLog : Bool
        Whether the log of the parameter value will be stored instead of the parameter itself (will prevent parameter from being negative).
    '''

    def __init__(self, val, prior_mean = None, prior_std = None, fit_par = False, asLog = False, device = torch.device('cpu')):
        '''

        Parameters
        ----------
        val : Float (or Array)
            The parameter value (or an array of node specific parameter values)
        prior_mean : Float
            Prior mean of the data value
        prior_std : Float
            Prior std of the value
        fit_par: Bool
            Whether the parameter value should be set to as a PyTorch Parameter
        device: torch.device
            Whether to run on CPU or GPU
        '''
        self.fit_par = fit_par
        self.device = device
        self.asLog = asLog
        self.fit_hyper = False

        if self.fit_par:
            if np.all(prior_mean != None) & np.all(prior_std != None):

                prior_mean_ts = torch.tensor(prior_mean, dtype=torch.float32).to(self.device)
                self.prior_mean = prior_mean_ts
                prior_std_ts = torch.tensor(prior_std, dtype=torch.float32).to(self.device)
                self.prior_var_inv = 1/prior_std_ts**2
                if type(val) is np.ndarray:
                    val = prior_mean + prior_std * torch.randn_like(torch.tensor(val, dtype=torch.float32)).detach().numpy()
                else:
                    val = prior_mean + prior_std * np.random.randn(1,)
                val_ts = torch.tensor(val, dtype=torch.float32).to(self.device)
                self.val = val_ts
                self.fit_hyper = True

            else:
                val_ts = torch.tensor(val, dtype=torch.float32).to(self.device)
                self.val = val_ts
        else:
            self.val = torch.tensor(val, dtype=torch.float32).to(self.device)




    def to(self, device):
        '''
        '''
        self.device = device
        
        self.val = self.val.to(self.device)


    def npValue(self):
        '''
        Returns
        --------
        NumPy of Value
            The parameter value(s) as a NumPy Array
        '''
        
        if self.asLog:
            return numpy.exp(self.val.detach().clone().cpu().numpy())
        else:
            return self.val.detach().clone().cpu().numpy()

    def value(self):
        '''
        Returns
        ---------
        Tensor of Value
            The parameter value(s) as a PyTorch Tensor
        '''


        if self.asLog:
            return torch.exp(self.val)
        else:
            return self.val

class AbstractParams:
    # This class stores the parameters used by a model. The parameters may be for the Neural Mass Model and/or Neuroimaging Modality.
    # It should be useable by both the pytorch model for training and a numpy model for parameter verification. 
    
    def __init__(self, **kwargs):
        # Define the parameters using the par data structure
        params ={}
        for var in kwargs:
            params[var] = kwargs[var]
        self.params = params
    def setParamsAsattr(self):
        # Returns a named list of paramters that are being fitted
        # Assumes the par datastructure is being used for parameters
        
        for var in self.params:
            setattr(self, var, self.params[var])


def dataloader(emp, epoch_size, TRperwindow):
    window_size = int(emp.shape[0] / TRperwindow)
    data_out = 0
    if len(emp.shape) == 2:
        node_size = emp.shape[1]
        length_ts = emp.shape[0]
        window_size = int(length_ts / TRperwindow)
        data_out = np.zeros((epoch_size, window_size, node_size, TRperwindow))
        for i_epoch in range(epoch_size):
            for i_win in range(window_size):
                data_out[i_epoch, i_win, :, :] = emp.T[:, i_win * TRperwindow:(i_win + 1) * TRperwindow]
    if len(emp.shape) == 3:
        node_size = emp.shape[2]
        length_ts = emp.shape[1]
        data_size = emp.shape[0]
        window_size = int(length_ts / TRperwindow)
        data_out = np.zeros((epoch_size, window_size, node_size, TRperwindow))
        for i_epoch in range(epoch_size):
            for i_win in range(window_size):
                data_out[i_epoch, i_win, :, :] = \
                    emp[i_epoch % data_size, i_win * TRperwindow:(i_win + 1) * TRperwindow, :].T
    return data_out

class AbstractNMM(torch.nn.Module):
    # This is the abstract class for the models (typically neural mass models) that are being trained. 
    # The neuroimaging modality might be integrated into the model as well. 

    def __init__(self, params):
        super(AbstractNMM, self).__init__() # May not want to enherit from torch.nn.Module in the future 
        self.params = params
        self.state_names = ["None"] # The names of the state variables of the model
        self.output_names = ["None"] # The variable to be used as output from the NMM, for purposes such as the input to an objective function
        self.track_params = [] # Which NMM Parameters to track over training
        
        
    def info(self):
        # Information about the model, which may be used by other classes to know which variables to use. 
        
        return {"state_names": self.state_names, 
                "output_names": self.output_names,
                "track_params": self.track_params}
            
    def setModelParameters(self):
        # Setting the parameters that will be optimized as either model parameters or 2ndLevel/hyper
        # parameters (for various optional features). 
        # This should be called in the __init__() function implementation for convenience if possible.
        """
        Sets the parameters of the model.
        """

        param_reg = []
        param_hyper = []

        
        var_names = [a for a in dir(self.params) if (type(getattr(self.params, a)) == par)]
        for var_name in var_names:
            var = getattr(self.params, var_name)
            if (var.fit_par):
                if var_name == 'lm':
                    size = var.val.shape
                    var.val = Parameter(var.val + 0.0*torch.randn(size[0], size[1])) 
                    var.prior_mean = Parameter(var.prior_mean)
                    var.prior_var_inv = Parameter(var.prior_var_inv)
                    param_reg.append(var.val)
                    if var.fit_hyper:
                        param_hyper.append(var.prior_mean)
                        param_hyper.append(var.prior_var_inv)
                    self.track_params.append(var_name)
                else:
                    var.val = Parameter(var.val) # TODO: This is not consistent with what user would expect giving a variance
                    var.prior_mean = Parameter(var.prior_mean)
                    var.prior_var_inv = Parameter(var.prior_var_inv)
                    param_reg.append(var.val)
                    if var.fit_hyper:
                        param_hyper.append(var.prior_mean)
                        param_hyper.append(var.prior_var_inv)
                    self.track_params.append(var_name)



        self.params_fitted = {'modelparameter': param_reg,'hyperparameter': param_hyper}
        
    def createIC(self, ver):
        # Create the initial conditions for the model state variables. 
        pass
        
    def createDelayIC(self, ver):
        # Creates a time series of state variables to represent their past values as needed when delays are used. 
        
        return torch.tensor(1.0) #Dummy variable if delays are not used
    
    def forward(self, external, hx, hE):
        # Run the mode simulation.
        # Returns a dictionary with values of state variables during the simulation.
        pass


class ParamsJR(AbstractParams):
    """
    A class for setting the parameters of a neural mass model for EEG data fitting.

    Attributes:
        A (par): The amplitude of the EPSP (excitatory post synaptic potential).
        a (par): A metric of the rate constant for the EPSP.
        B (par): The amplitude of the IPSP (inhibitory post synaptic potential).
        b (par): A metric of the rate constant for the IPSP.
        g (par): The gain of ???.
        c1 (par): The connectivity parameter from the pyramidal to excitatory interneurons.
        c2 (par): The connectivity parameter from the excitatory interneurons to the pyramidal cells.
        c3 (par): The connectivity parameter from the pyramidal to inhibitory interneurons.
        c4 (par): The connectivity parameter from the inhibitory interneurons to the pyramidal cells.
        std_in (par): The standard deviation of the input noise.
        vmax (par): The maximum value of the sigmoid function.
        v0 (par): The midpoint of the sigmoid function.
        r (par): The slope of the sigmoid function.
        y0 (par): ???.
        mu (par): The mean of the input.
        k (par): ???.
        cy0 (par): ???.
        ki (par): ???.
    """
    def __init__(self, **kwargs):
        """
        Initializes the ParamsJR object.

        Args:
            **kwargs: Keyword arguments for the model parameters.

        Returns:
            None
        """
        
        super(ParamsJR, self).__init__(**kwargs)
        params = {
            "A ": par(3.25), 
            "a": par(100), 
            "B": par(22), 
            "b": par(50), 
            "g": par(1000),
            
            "c1": par(135), 
            "c2": par(135 * 0.8), 
            "c3 ": par(135 * 0.25), 
            "c4": par(135 * 0.25),
            
            "std_in": par(100), 
            "vmax": par(5), 
            "v0": par(6), 
            "r": par(0.56), 
            "y0": par(2),
            
            "mu": par(.5), 
            "k": par(5), 
            "cy0": par(5), 
            "ki": par(1)
        }
        for var in params:
            if var not in self.params:
                self.params[var] = params[var]
        
        self.setParamsAsattr()

class RNNJANSEN(AbstractNMM):
    """
    A module for forward model (JansenRit) to simulate EEG signals

    Attibutes
    ---------
    state_size : int
        Number of states in the JansenRit model

    output_size : int
        Number of EEG channels.

    node_size: int
        Number of ROIs

    hidden_size: int
        Number of step_size for each sampling step

    step_size: float
        Integration step for forward model

    tr : float # TODO: CHANGE THE NAME TO sampling_rate
        Sampling rate of the simulated EEG signals

    TRs_per_window: int # TODO: CHANGE THE NAME
        Number of EEG signals to simulate

    sc: ndarray (node_size x node_size) of floats
        Structural connectivity

    lm: ndarray of floats
        Leadfield matrix from source space to EEG space

    dist: ndarray of floats
        Distance matrix

    use_fit_gains: bool
        Flag for fitting gains. 1: fit, 0: not fit

    use_fit_lfm: bool
        Flag for fitting the leadfield matrix. 1: fit, 0: not fit

    # FIGURE OUT: g, c1, c2, c3, c4: tensor with gradient on
    #     model parameters to be fit

    std_in: tensor with gradient on
        Standard deviation for input noise

    params: ParamsJR
        Model parameters object.


    Methods
    -------
    createIC(self, ver):
        Creates the initial conditions for the model.

    createDelayIC(self, ver):
        Creates the initial conditions for the delays.

    setModelParameters(self):
        Sets the parameters of the model.

    forward(input, noise_out, hx)
        Forward pass for generating a number of EEG signals with current model parameters

    """

    def __init__(self, params: ParamsJR, node_size=200,
                 TRs_per_window=20, step_size=0.0001, output_size= 62, tr=0.001, sc=np.ones((200,200)), lm=np.ones((62,200)), dist=np.ones((200,200)), use_fit_gains=True, mask = np.ones((200,200))):
        """
        Parameters
        ----------
        node_size: int
            Number of ROIs
        TRs_per_window: int # TODO: CHANGE THE NAME
            Number of EEG signals to simulate
        step_size: float
            Integration step for forward model
        output_size : int
            Number of EEG channels.
        tr : float # TODO: CHANGE THE NAME TO sampling_rate
            Sampling rate of the simulated EEG signals
        sc: ndarray node_size x node_size float array
            Structural connectivity
        lm: ndarray float array
            Leadfield matrix from source space to EEG space
        dist: ndarray float array
            Distance matrix
        use_fit_gains: bool
            Flag for fitting gains. 1: fit, 0: not fit
        params: ParamsJR
            Model parameters object.
        """
        method_arg_type_check(self.__init__) # Check that the passed arguments (excluding self) abide by their expected data types

        super(RNNJANSEN, self).__init__(params)
        
        self.pop_names = np.array(['P', 'E', 'I'])
        self.state_names = np.array(['current', 'voltage'])
        self.output_names = ["eeg"]
        self.track_params = [] #Is populated during setModelParameters()

        self.model_name = "JR"
        self.pop_size = 3  # 3 populations JR
        self.state_size = 2  # 2 states in each population
        self.tr = tr  # tr ms (integration step 0.1 ms)
        self.step_size = torch.tensor(step_size, dtype=torch.float32)  # integration step 0.1 ms
        self.steps_per_TR = int(tr / step_size)
        self.TRs_per_window = TRs_per_window  # size of the batch used at each step
        self.node_size = node_size  # num of ROI
        self.output_size = output_size  # num of EEG channels
        self.sc = sc  # matrix node_size x node_size structure connectivity
        self.dist = torch.tensor(dist, dtype=torch.float32)
        self.lm = lm
        self.use_fit_gains = use_fit_gains  # flag for fitting gains
        #self.use_fit_lfm = use_fit_lfm
        self.params = params
        self.output_size = lm.shape[0]  # number of EEG channels
        self.mask = mask

        self.setModelParameters()
        self.setModelSCParameters()

    def createIC(self, ver):
        """
        Creates the initial conditions for the model.

        Parameters
        ----------
        ver : int # TODO: ADD MORE DESCRIPTION
            Initial condition version. (in the JR model, the version is not used. It is just for consistency with other models)

        Returns
        -------
        torch.Tensor
            Tensor of shape (node_size, state_size) with random values between `state_lb` and `state_ub`.
        """

        state_lb = -0.1
        state_ub = 0.1

        return torch.tensor(np.random.uniform(state_lb, state_ub, (self.node_size, self.pop_size, self.state_size)),
                             dtype=torch.float32)

    def createDelayIC(self, ver):
        """
        Creates the initial conditions for the delays.

        Parameters
        ----------
        ver : int
            Initial condition version. (in the JR model, the version is not used. It is just for consistency with other models)

        Returns
        -------
        torch.Tensor
            Tensor of shape (node_size, delays_max) with random values between `state_lb` and `state_ub`.
        """

        delays_max = 500
        state_ub = 0.1
        state_lb = 0

        return torch.tensor(np.random.uniform(state_lb, state_ub, (self.node_size,  delays_max)), dtype=torch.float32)

    def setModelSCParameters(self):
        """
        Sets the parameters of the model.
        """
         # Create the arrays in numpy
        small_constant = 0.05
        n_nodes = self.node_size
        zsmat = zeros((self.node_size, self.node_size)) + small_constant 
        w_p2e = zsmat.copy() # the pyramidal to excitatory interneuron cross-layer gains
        w_p2i = zsmat.copy() # the pyramidal to inhibitory interneuron cross-layer gains
        w_p2p = zsmat.copy() # the pyramidal to pyramidal cells same-layer gains
        
        # Set w_bb, w_ff, and w_ll as attributes as type Parameter if use_fit_gains is True
        if self.use_fit_gains:
            self.w_bb = ptParameter(pttensor(w_p2i, dtype=ptfloat32))
            self.w_ff = ptParameter(pttensor(w_p2e, dtype=ptfloat32))
            self.w_ll = ptParameter(pttensor(w_p2p, dtype=ptfloat32))
            self.params_fitted['modelparameter'].append(self.w_ll)
            self.params_fitted['modelparameter'].append(self.w_ff)
            self.params_fitted['modelparameter'].append(self.w_bb)
        else:
            self.w_bb = torch.tensor(np.zeros((self.node_size, self.node_size)), dtype=torch.float32)
            self.w_ff = torch.tensor(np.zeros((self.node_size, self.node_size)), dtype=torch.float32)
            self.w_ll = torch.tensor(np.zeros((self.node_size, self.node_size)), dtype=torch.float32)

        
    def forward(self, external, hx, hE):
        """
        This function carries out the forward Euler integration method for the JR neural mass model,
        with time delays, connection gains, and external inputs considered. Each population (pyramidal,
        excitatory, inhibitory) in the network is modeled as a non-linear second order system. The function
        updates the state of each neural population and computes the EEG signals at each time step.

        Parameters
        ----------
        external : torch.Tensor
            Input tensor of shape (batch_size, num_ROIs) representing the input to the model.
        hx : Optional[torch.Tensor]
            Optional tensor of shape (batch_size, state_size, num_ROIs) representing the initial hidden state.
        hE : Optional[torch.Tensor]
            Optional tensor of shape (batch_size, num_ROIs, delays_max) representing the initial delays.

        Returns
        -------
        next_state : dict
            Dictionary containing the updated current state, EEG signals, and the history of
            each population's current and voltage at each time step.

        hE : torch.Tensor
            Tensor representing the updated history of the pyramidal population's current.
        """

        # Generate the ReLU module
        m = torch.nn.ReLU()

        # Define some constants
        con_1 = torch.tensor(1.0, dtype=torch.float32) # Define constant 1 tensor
        conduct_lb = 0  # lower bound for conduct velocity
        u_2ndsys_ub = 500  # the bound of the input for second order system
        noise_std_lb = 0  # lower bound of std of noise
        lb = 0.  # lower bound of local gains
        k_lb = 0.5  # lower bound of coefficient of external inputs


        # Defining NMM Parameters to simplify later equations
        #TODO: Change code so that params returns actual value used without extras below
        A = 0 * con_1 + m(self.params.A.value())
        a = 0 * con_1 + m(self.params.a.value())
        B = 0 * con_1 + m(self.params.B.value())
        b = 0 * con_1 + m(self.params.b.value())
        g = (lb * con_1 + m(self.params.g.value()))
        c1 = (lb * con_1 + m(self.params.c1.value()))
        c2 = (lb * con_1 + m(self.params.c2.value()))
        c3 = (lb * con_1 + m(self.params.c3.value()))
        c4 = (lb * con_1 + m(self.params.c4.value()))
        std_in = (noise_std_lb * con_1 + m(self.params.std_in.value())) #around 20
        vmax = self.params.vmax.value()
        v0 = self.params.v0.value()
        r = self.params.r.value()
        y0 = self.params.y0.value()
        mu = (0.1 * con_1 + m(self.params.mu.value()))
        k = (5.0 * con_1 + m(self.params.k.value()))
        cy0 = self.params.cy0.value()
        ki = self.params.ki.value()

        g_f = (lb * con_1 + m(self.params.g_f.value()))
        g_b = (lb * con_1 + m(self.params.g_b.value()))
        lm = self.params.lm.value()

        next_state = {}

        P = hx[:, 0:1, 0]  # current of pyramidal population
        E = hx[:, 1:2, 0]  # current of excitory population
        I = hx[:, 2:3, 0]  # current of inhibitory population

        Pv = hx[:, 0:1, 1]  # voltage of pyramidal population
        Ev = hx[:, 1:2, 1]  # voltage of exictory population
        Iv = hx[:, 2:3, 1]  # voltage of inhibitory population
        #print(M.shape)
        dt = self.step_size
        n_nodes = self.node_size
        n_chans = self.output_size
        
        sc = self.sc
        ptsc = pttensor(sc, dtype=ptfloat32)

        if self.sc.shape[0] > 1:

            # Update the Laplacian based on the updated connection gains w_bb.
            w_b = ptexp(self.w_bb) * ptsc
            w_n_b = w_b / ptnorm(w_b)*pttensor(self.mask, dtype=ptfloat32)
            self.sc_m_b = w_n_b
            dg_b = -ptdiag(ptsum(w_n_b, dim=1))

            # Update the Laplacian based on the updated connection gains w_ff.
            w_f = ptexp(self.w_ff) * ptsc     
            w_n_f = w_f / ptnorm(w_f)*pttensor(self.mask, dtype=ptfloat32)
            self.sc_m_f = w_n_f
            dg_f = -ptdiag(ptsum(w_n_f, dim=1))

            # Update the Laplacian based on the updated connection gains w_ll.
            w_l = ptexp(self.w_ll) * ptsc         
            w_n_l = (0.5 * (w_l + pttranspose(w_l, 0, 1))) / ptnorm(0.5 * (w_l + pttranspose(w_l, 0, 1)))*pttensor(self.mask, dtype=ptfloat32)
            self.sc_fitted = w_n_l
            dg_l = -ptdiag(ptsum(w_n_l, dim=1))
        else:
            l_s = torch.tensor(np.zeros((1, 1)), dtype=torch.float32) #TODO: This is not being called anywhere
            dg_l = 0
            dg_b = 0
            dg_f = 0
            w_n_l = 0
            w_n_b = 0
            w_n_f = 0

        self.delays = (self.dist / mu).type(torch.int64)

        # Placeholder for the updated current state
        current_state = ptzeros_like(hx)

        # Initializing lists for the history of the EEG signals, as well as each population's current and voltage.
        eeg_window = []
        E_window = []
        I_window = []
        P_window = []
        Ev_window = []
        Iv_window = []
        Pv_window = []
        states_window = []

        # Use the forward model to get EEG signal at the i-th element in the window.
        for i_window in range(self.TRs_per_window):
            for step_i in range(self.steps_per_TR):
                Ed = pttranspose(hE.clone().gather(1,self.delays), 0, 1)
                
                LEd_p2i = ptreshape(ptsum(w_n_b * Ed, 1), (n_nodes, 1)) + ptmatmul(dg_b, P)
                LEd_p2e = ptreshape(ptsum(w_n_f * Ed, 1), (n_nodes, 1)) + ptmatmul(dg_f, P)
                LEd_p2p = ptreshape(ptsum(w_n_l * Ed, 1), (n_nodes, 1)) + ptmatmul(dg_l, P)

                # external input
                u_stim = external[:, step_i:step_i + 1, i_window, 0]
                
                # Stochastic / noise term
                P_noise = std_in * ptrandn(n_nodes, 1) 
                E_noise = std_in * ptrandn(n_nodes, 1)
                I_noise = std_in * ptrandn(n_nodes, 1)
                
                # Compute the firing rate for each neural populatin 
                # at every node using the wave-to-pulse (sigmoid) functino
                # (vmax = max value of sigmoid, v0 = midpoint of sigmoid)
                P_sigm = vmax / ( 1 + ptexp ( r*(v0 -  (E-I) ) ) )
                E_sigm = vmax / ( 1 + ptexp ( r*(v0 - (c1*P) ) ) )
                I_sigm = vmax / ( 1 + ptexp ( r*(v0 - (c3*P) ) ) )
                # Sum the four different input types into a single input value for each neural 
                # populatin state variable
                # The four input types are:
                # - Local      (L)      - from other neural populations within a node (E->P,P->I, etc.)
                # - Long-range (L-R)    - from other nodes in the network, weighted by the long-range 
                #                         connectivity matrices, and time-delayed
                # - Noise      (N)      - stochastic noise input
                # - External   (E)      - external stimulation, eg from TMS or sensory stimulus
                #
                #        Local    Long-range   Noise   External
                rP =     P_sigm  + g*LEd_p2p   + P_noise + k*ki*u_stim 
                rE =  c2*E_sigm  + g_f*LEd_p2e + E_noise          
                rI =  c4*I_sigm  + g_b*LEd_p2i + I_noise 
                
                # Apply some additional scaling
                rP_bd = u_2ndsys_ub * pttanh(rP / u_2ndsys_ub)
                rE_bd = u_2ndsys_ub * pttanh(rE / u_2ndsys_ub)
                rI_bd = u_2ndsys_ub * pttanh(rI / u_2ndsys_ub)

                # Compute d/dt   ('_tp1' = state variable at time t+1) 
                P_tp1 =  P + dt * Pv
                E_tp1 =  E + dt * Ev
                I_tp1 =  I + dt * Iv
                Pv_tp1 = Pv + dt * ( A*a*rP_bd  -  2*a*Pv  -  a**2 * P )
                Ev_tp1 = Ev + dt * ( A*a*rE_bd  -  2*a*Ev  -  a**2 * E )
                Iv_tp1 = Iv + dt * ( B*b*rI_bd  -  2*b*Iv  -  b**2 * I )

                # Calculate the saturation for model states (for stability and gradient calculation).
                
                # Add some additional saturation on the model states
                # (for stability and gradient calculation).
                P = 1000*pttanh(P_tp1/1000)
                E = 1000*pttanh(E_tp1/1000)
                I = 1000*pttanh(I_tp1/1000)
                Pv = 1000*pttanh(Pv_tp1/1000)
                Ev = 1000*pttanh(Ev_tp1/1000)
                Iv = 1000*pttanh(Iv_tp1/1000)
                #print('after M', M.shape)
                # Update placeholders for pyramidal buffer
                hE[:, 0] = P[:,0]

            # Capture the states at every tr in the placeholders for checking them visually.

            # Capture the states at every tr in the placeholders for checking them visually.
            hE = ptcat([P, hE[:, :-1]], dim=1)  # update placeholders for pyramidal buffer

            # Capture the states at every tr in the placeholders which is then used in the cost calculation.
            lm_t = (lm.T / torch.sqrt((lm ** 2).sum(1))).T
            lm_t_dm = (lm_t - 1 / n_chans * torch.matmul(torch.ones((1,n_chans)), lm_t))
            temp = cy0 * torch.matmul(lm_t_dm, E-I) - 1 * y0
            eeg_window.append(temp)
            states_window.append(torch.cat([torch.cat([P, E, I], dim=1)[:,:,np.newaxis], \
                                   torch.cat([Pv, Ev, Iv], dim=1)[:,:,np.newaxis]], dim=2)[:,:,:,np.newaxis])
        # Update the current state.
        self.lm_t = lm_t_dm
        
        current_state = torch.cat([torch.cat([P, E, I], dim=1)[:,:,np.newaxis], \
                                   torch.cat([Pv, Ev, Iv], dim=1)[:,:,np.newaxis]], dim=2)
        next_state['current_state'] = current_state
        next_state['eeg'] = torch.cat(eeg_window, dim=1)
        next_state['states'] = torch.cat(states_window, dim=3)


        return next_state, hE
        


class AbstractLoss:
    # This is the abstract class for objective function components, or for a custom objective function with multiple components. 

    def __init__(self, simKey = None, device = torch.device('cpu')):
    
        self.simKey = simKey #This is a string key to extract from the dictionary of simulation outputs the time series used by the objective function
        device = device
    
    def loss(self, simData, empData):
        # Calculates a loss to be backpropagated through
        # If the objective function needs additional info, it should be defined at initialization so that the parameter fitting paradigms don't need to change
        
        # simData: is a dictionary of simulated state variable/neuroimaging modality time series. Typically accessed as simData[self.simKey].
        # empData: is the target either as a time series or a calculated phenomena metric
        
        pass

class CostsTS(AbstractLoss):
    def __init__(self, simKey):
        super(CostsTS, self).__init__(simKey)
        self.simKey = simKey

    def loss(self, simData: dict, empData: torch.Tensor):
        """
        Calculate the Pearson Correlation between the simFC and empFC.
        From there, compute the probability and negative log-likelihood.
        
        Parameters
        ----------
        simData: dict of tensor with node_size X datapoint
            simulated EEG
        empData: tensor with node_size X datapoint
            empirical EEG
        """
        method_arg_type_check(self.loss) # Check that the passed arguments (excluding self) abide by their expected data types
        sim = simData[self.simKey]
        emp = empData

        losses = torch.sqrt(torch.mean((sim - emp) ** 2))  #
        return losses

class CostsJR(AbstractLoss):
    def __init__(self, model):
        self.mainLoss = CostsTS("eeg")
        self.simKey = "eeg"
        self.model = model

    def loss(self, simData: dict, empData: torch.Tensor):

        method_arg_type_check(self.loss) # Check that the passed arguments (excluding self) abide by their expected data types
        sim = simData
        emp = empData

        model = self.model

        # define some constants
        lb = 0.001

        w_cost = 10

        # define the relu function
        m = torch.nn.ReLU()

        exclude_param = []
        if model.use_fit_gains:
            exclude_param.append('gains_con') #TODO: Is this correct?



        loss_main = self.mainLoss.loss(sim, emp)

        loss_EI = 0
        loss_prior = []

        variables_p = [a for a in dir(model.params) if (type(getattr(model.params, a)) == par)]

        for var_name in variables_p:
            var = getattr(model.params, var_name)
            if var.fit_hyper and \
                        var_name not in exclude_param:
                loss_prior.append(torch.sum(( m(var.prior_var_inv) * \
                                            (m(var.val) - m(var.prior_mean)) ** 2)) \
                                  + torch.sum(-torch.log( m(var.prior_var_inv))))

        # total loss
        loss = 0.1 * w_cost * loss_main + 1 * sum(loss_prior) + 1 * loss_EI
        return loss, loss_main        
        
import torch.optim as optim


import pickle
from sklearn.metrics.pairwise import cosine_similarity


class Recording():
    '''    
    This class is responsible for holding timeseries of empirical and simulated data. It is: 
        - Part of the input and output of Model_fitting and Model_simulation[future]. 
        - It is the format expected by the visualization function of whobpyt. 
    
    However, the Recording class is not used within and across the NMM and Modals, as a simpler dictionary of tensors is used in those contexts. 

    Numerical simulation internals don't necessarily use this data structure, as calculations may be more efficient as the transpose: ts_length x num_regions.
    
    
    Attributes
    -------------
    data : Numpy Array or Tensor of dimensions num_regions x ts_length
        The time series data, either empirical or simulated
    step_size : Float
        The step size of the time points in the data class
    modality : String
        The name of the modality of the time series   
    numNodes : Int
        The number of nodes it time series.
    length : Int 
        The number of time points in the time series. 
    
    
    '''
        
    def __init__(self, data, step_size, modality = ""):
        '''
        
        Parameters
        -----------
        
        data : Numpy Array or Tensor of dimensions num_regions x ts_length
            The time series data, either empirical or simulated
        step_size : Float
            The step size of the time points in the data class
        modality : String
            The name of the modality of the time series
        
        '''
        
        
        if not(torch.is_tensor(data)):
            data = torch.tensor(data) # Store as Tensor
        
        self.data = data
        self.step_size = step_size
        self.modality = modality
        self.numNodes = self.data.shape[0]
        self.length = self.data.shape[1]
    
    def pyTS(self):
        '''
        Returns
        --------
        Tensor of num_regions x ts_length
        
        '''
        
        return self.data
    
    def npTS(self):
        '''
        Returns
        ---------
        Numpy Array of num_regions x ts_length
        
        '''
        
        return self.data.cpu().numpy()
        
    def npNodeByTime(self):
        '''
        Returns
        ---------
        Numpy Array of num_regions x ts_length        
        
        '''
        
        return self.data.cpu().numpy()
        
    def npTimeByNodes(self):
        '''
        Returns
        ---------
        Numpy Array of ts_length x num_regions        
        
        '''
        
        return self.data.cpu().numpy().T
        
    def length(self):
        '''
        Returns
        ---------
        The time series length
        
        '''   
        
        return self.length
        
    def npResample(self):
        '''
        This outputs resampled data used for figures (TODO: Not yet implemented)        
        
        '''
        
        pass
    
    def windowedTensor(self, TPperWindow):
        '''
        This method is called by the Model_fitting Class during training to reshape the data into windowed segments (adds another dimension).
        
        Parameters
        -----------
        TPperWindow : Int
            The number of time points in the window that will be back propagated
        
        Returns
        ---------
        Tensor: num_windows x num_regions x window_length
            The time series data in a windowed format
        '''
        
        node_size = self.data.shape[0]
        length_ts = self.data.shape[1]
        num_windows = int(length_ts / TPperWindow)
        data_out = np.zeros((num_windows, node_size, TPperWindow))
    
        for i_win in range(num_windows):
            data_out[i_win, :, :] = self.data[:, i_win * TPperWindow:(i_win + 1) * TPperWindow]
    
        return data_out

class AbstractFitting():
    # AbstractFitting is a template class for different parameter optimization or machine learning paradigms to inherit from. 

    def __init__(self, model: AbstractNMM, cost: AbstractLoss, device = torch.device('cpu')):
        # Initializing the class
        
        self.model = model
        self.cost = cost
        self.device = device
        
        self.trainingStats = TrainingStats(self.model)
        self.lastRec = None # Saves the last simulation during training
    
    
    def save(self, filename):
        # Saving the entire class
        with open(filename, 'wb') as f:
            pickle.dump(self, f)
        
        
    def train():
        # This function is for training of a model. 
        pass
    
    
    def evaluate():
        # The function is intended to calculate statistics as they are calculated during training, but not updating model parameters. 
        pass
    
    
    def simulate():
        # This function is intended for running some fixed duration of simulation.
        pass
    
    



class TrainingStats:
    '''
    This class is responsible for recording stats during training (it replaces OutputNM) including:
        - The training and validation losses over time
        - The change in model parameters over time
        - changing hyper parameters over time like learing rates TODO

    These are things typically recorded on a per window/epoch basis

    Attributes
    ------------
    model_info : Dict
        Information about model being tracked during training.
    track_params : List
        List of parameter names being tracked during training.
    loss : List
        A list of loss values over training.
    connectivity : List
        A list of connectivity values over training.
    leadfield : List
        A list of leadfield matrices over training.
    fit_params : Dict
        A dictionary of lists where the key is the parameter name and the value is the list of parameter values over training.

    '''

    def __init__(self, model):
        '''

        Parameters
        -----------
        model : AbstractNMM
            A model for which stats will be recorded during training.

        '''

        model_info = model.info()
        self.track_params = model.track_params

        self.loss = []

        self.connectivity = []
        self.leadfield = []

        self.fit_params = {}
        self.outputs = {}
        self.states = {}
        self.states_mode = {}
        self.states_tha = {}

    def save(self, filename):
        '''
        Parameters
        ------------
        filename : String
            The filename to use to save the TrainingStats as a pickle object.

        '''

        with open(filename, 'wb') as f:
            pickle.dump(self, f)

    def reset(self):
        '''
        Resets the attributes of the model to a pre-training state.

        '''

        self.loss = []

        self.network_con = []
        self.leadfield = []

        self.fit_params = {}

        self.outputs = {}
        self.states = {}
        self.states_mode = {}
        self.states_tha = {}

    def updateOutputs(self, newValue, mode: str):
        self.outputs[mode] = newValue

    def updateStates(self, newValue, mode: str):
        self.states[mode] = newValue
    def updateStatesTha(self, newValue, mode: str):
        self.states_tha[mode] = newValue
    def updateStatesMode(self, newValue, mode: str):
        self.states_mode[mode] = newValue

    def appendLoss(self, newValue):
        """
        Append Trainig Loss

        Parameters
        -----------
        newValue : Float
            The loss value of objective function being tracked.

        """
        self.loss.append(newValue)

    def appendSC(self, newValue):
        """
        Append Network Connections

        Parameters
        -----------
        newValue : Array
            Current state of the structural connectivity being tracked.

        """
        self.connectivity.append(newValue)

    def appendLF(self, newValue):
        """
        Append Lead Field Loss

        Parameters
        -----------
        newValue : Array
            Current state of a lead field matrix being tracked.

        """
        self.leadfield.append(newValue)

    def appendParam(self, newValues):
        """
        Append Fit Parameters

        Parameters
        ----------
        newValues : Dict
            Dictionary with current states of each model parameter being tracked.

        """
        if (self.fit_params == {}):
            for name in newValues.keys():
                self.fit_params[name] = [newValues[name]]
        else:
            for name in newValues.keys():
                self.fit_params[name].append(newValues[name])


class Model_fitting(AbstractFitting):
    """
    This Model_fitting class is able to fit resting state data or evoked potential data
    for which the input training data is empty or some stimulus to one or more NMM nodes,
    and the label is an associated empirical neuroimaging recording.

    Studies which consider different kinds of input, such as if SC or some other variable
    is associated with an empirical recording, must use a different fitting class.

    Attributes
    ----------
    model: AbstractNMM
        Whole Brain Model to Simulate
    cost: AbstractLoss
        A particular objective function which the model will be optimized for.
    trainingStats: TrainingStats
        Information about objective function loss and parameter values over training windows/epochs
    lastRec: Recording
        The last simulation of fitting(), evaluation(), or simulation()
    device : torch.device
        Whether the fitting is to run on CPU or GPU
    """

    def __init__(self, model: AbstractNMM, cost: AbstractLoss, device = torch.device('cpu')):
        """
        Parameters
        ----------
        model: AbstractNMM
            Whole Brain Model to Simulate
        cost: AbstractLoss
            A particular objective function which the model will be optimized for.
        device : torch.device
            Whether the fitting is to run on CPU or GPU
        """
        #method_arg_type_check(self.__init__) # Check that the passed arguments (excluding self) abide by their expected data types

        self.model = model
        self.cost = cost

        self.device = device

        self.trainingStats = TrainingStats(self.model)
        #self.lastRec = None #A dictionary or Recordings of the last simulation preformed (either training or evaluation)

        #self.u = None #This is the ML "Training Input"
        #self.empTS = ts #This is the ML "Training Labels" - A list

    def save(self, filename):
        """
        Parameters
        ----------
        filename: String
            filename to use when saving object to file
        """
        with open(filename, 'wb') as f:
            pickle.dump(self, f)

    def train(self, u, empRec,
              num_epochs: int, TPperWindow: int, warmupWindow: int = 0, learningrate: float = 0.05, lr_2ndLevel: float = 0.05, lr_scheduler: bool = False, empRecSec = None, X=None, hE=None):
        """
        Parameters
        ----------
        u: type
           This stimulus is the ML "Training Input"
        empRec: list of Recording
            This is the ML "Training Labels"
        num_epochs: int
            the number of times to go through the entire training data set
        TPperWindow: int
            Number of Empirical Time Points per window. model.forward does one window at a time.
        learningrate: float
            rate of gradient descent
        lr_2ndLevel: float
            learning rate for priors of model parameters, and possibly others
        lr_scheduler: bool
            Whether to use the learning rate scheduler
        """
        method_arg_type_check(self.train, exclude = ['u', 'empRec']) # Check that the passed arguments (excluding self) abide by their expected data types
        emp = []
        emp.append(empRec)
        if empRecSec is not None:
            emp.append(empRecSec)
        # Define two different optimizers for each group
        modelparameter_optimizer = optim.Adam(self.model.params_fitted['modelparameter'], lr=learningrate, eps=1e-7)
        hyperparameter_optimizer = optim.Adam(self.model.params_fitted['hyperparameter'], lr=lr_2ndLevel, eps=1e-7)



        

        # define masks for getting lower triangle matrix indices
        mask = np.tril_indices(self.model.node_size, -1)
        mask_e = np.tril_indices(self.model.output_size, -1)

        # initial state
        if X is None:
            if self.model.model_name == "JR_thalam":
                X, X_tha = self.model.createIC(ver = 0)
            elif self.model.model_name == "JR_mode":
                X, X_mode = self.model.createIC(ver = 0)
            else:
                X = self.model.createIC(ver = 0)
        # initials of history of E
        if hE is None:
            hE = self.model.createDelayIC(ver = 0)

        # LOOP 1/4: Number of Training Epochs
        for i_epoch in range(num_epochs):
            
            if self.model.model_name == "HGF":
                # initial state
                X = self.model.createIC(ver = 0)
                #print(X.shape)
                # initials of history of E
                hE = self.model.createDelayIC(ver = 0)
                #print(hE.shape)
            # Perform the training in windows.
            if i_epoch == 0:
                warmup_windows = 0

            else:
                warmup_windows = warmupWindow
            # TRAINING_STATS: placeholders for the history of trainingStats
            loss_his = []  # loss placeholder to take the average for the epoch at the end of the epoch

            print("Epoch: ", i_epoch)

            # LOOP 2/4: Number of Recordings in the Training Dataset

            # TIME SERIES: Create placeholders for the simulated states and outputs of entire time series corresponding to one recording
            windListDict = {} # A Dictionary with a List of windowed time series
            
            if self.model.model_name == "JR_thalam":
                for name in ['states', 'states_tha'] + self.model.output_names:
                    windListDict[name] = []
            elif self.model.model_name == "JR_mode":
                for name in ['states', 'states_mode'] + self.model.output_names:
                    windListDict[name] = []
            else:
                for name in ['states'] + self.model.output_names:
                    windListDict[name] = []





            # initial the external inputs
            external = torch.tensor(
                np.zeros([self.model.node_size, self.model.steps_per_TR, self.model.TRs_per_window, self.model.pop_size]),
                dtype=torch.float32)

            windowedTS = empRec[i_epoch]
            if empRecSec is not None:
                windowedTS_sec = empRecSec[i_epoch]
            for TR_i in range(warmup_windows):
                



                # Use the model.forward() function to update next state and get simulated EEG in this batch.
                if self.model.model_name == "JR_thalam":
                    next_window, hE_new = self.model(external, X, X_tha, hE)
                elif self.model.model_name == "JR_mode":
                    next_window, hE_new = self.model(external, X, X_mode, hE)
                else:
                    next_window, hE_new = self.model(external, X, hE)
                #print(next_window['current_state'])
                if self.model.model_name == "JR_thalam":
                    X_tha = torch.tensor(next_window['current_state_tha'].detach().numpy(), dtype=torch.float32)
                if self.model.model_name == "JR_mode":
                    X_mode = torch.tensor(next_window['current_state_mode'].detach().numpy(), dtype=torch.float32)
                X = torch.tensor(next_window['current_state'].detach().numpy(), dtype=torch.float32)
                """if self.model.model_name == "JR_thalam":
                    X_tha = next_window['current_state_tha'].detach().clone()"""
                hE = torch.tensor(hE_new.detach().numpy(), dtype=torch.float32)
            print(X.shape)
            # LOOP 3/4: Number of windowed segments for the recording
            for win_idx in range(windowedTS.shape[0]):

                # Reset the gradient to zeros after update model parameters.
                hyperparameter_optimizer.zero_grad()
                modelparameter_optimizer.zero_grad()

                # if the external not empty
                if not isinstance(u, int):
                    external = torch.tensor(
                        (u[:, :, win_idx * self.model.TRs_per_window:(win_idx + 1) * self.model.TRs_per_window]),
                        dtype=torch.float32)

                # LOOP 4/4: The loop within the forward model (numerical solver), which is number of time points per windowed segment
                if self.model.model_name == "JR_thalam":
                    next_window, hE_new = self.model(external, X, X_tha, hE)
                elif self.model.model_name == "JR_mode":
                    next_window, hE_new = self.model(external, X, X_mode, hE)
                else:
                    next_window, hE_new = self.model(external, X, hE)

                # Get the batch of empirical signal.
                ts_window = torch.tensor(windowedTS[win_idx, :, :], dtype=torch.float32)
                if self.model.model_name in  ['RWWMM', 'RWW_EEG_BOLD']:
                    ts_sec_window = torch.tensor(windowedTS_sec[win_idx, :, :], dtype=torch.float32)
                #print(next_window['bold'].shape, next_window['states'].shape)
                # calculating loss
                if self.model.model_name in  ['RWWMM', 'RWW_EEG_BOLD']:
                    loss, loss_main = self.cost.loss(next_window, ts_window, ts_sec_window)
                else:
                    loss, loss_main = self.cost.loss(next_window, ts_window)

                # TIME SERIES: Put the window of simulated forward model.
                if self.model.model_name == "JR_thalam":
                    for name in ['states', 'states_tha'] + self.model.output_names:
                        windListDict[name].append(next_window[name].detach().cpu().numpy())
                elif self.model.model_name == "JR_mode":
                    for name in ['states', 'states_mode'] + self.model.output_names:
                        windListDict[name].append(next_window[name].detach().cpu().numpy())
                else:
                    for name in ['states'] + self.model.output_names:
                        windListDict[name].append(next_window[name].detach().cpu().numpy())

                # TRAINING_STATS: Adding Loss for every training window (corresponding to one backpropagation)
                loss_his.append(loss_main.detach().cpu().numpy())

                # Calculate gradient using backward (backpropagation) method of the loss function.
                loss.backward(retain_graph=True)

                # Optimize the model based on the gradient method in updating the model parameters.
                hyperparameter_optimizer.step()
                modelparameter_optimizer.step()



                # last update current state using next state...
                # (no direct use X = X_next, since gradient calculation only depends on one batch no history)
                X = next_window['current_state'].detach().clone() # dtype=torch.float32
                if self.model.model_name == "JR_thalam":
                    X_tha = next_window['current_state_tha'].detach().clone()
                if self.model.model_name == "JR_mode":
                    X_mode = next_window['current_state_mode'].detach().clone()
                hE = hE_new.detach().clone() #dtype=torch.float32

                trackedParam = {}
                exclude_param = ['gains_con'] #This stores SC and LF which are saved seperately
                if(self.model.track_params):
                    for par_name in self.model.track_params:
                        var = getattr(self.model.params, par_name)
                        if (var.fit_par):
                            trackedParam[par_name] = var.value().detach().cpu().numpy().copy()
                            if var.fit_hyper:
    
                                trackedParam[par_name + "_prior_mean"] = var.prior_mean.detach().cpu().numpy().copy()
                                trackedParam[par_name + "_prior_var_inv"] = var.prior_var_inv.detach().cpu().numpy().copy()
                for key, value in self.model.state_dict().items():
                    if key not in exclude_param:
                        trackedParam[key] = value.detach().cpu().numpy().ravel().copy()
                self.trainingStats.appendParam(trackedParam)
                # Saving the SC and/or Lead Field State at Every Epoch
                if self.model.use_fit_gains:
                    self.trainingStats.appendSC(self.model.sc_fitted.detach().cpu().numpy())
            # TIME SERIES: Concatenate all windows together to get one recording
            if self.model.model_name == "JR_thalam":
                for name in ['states', 'states_tha'] + self.model.output_names:
                    windListDict[name] = np.concatenate(windListDict[name], axis=len(windListDict[name][0].shape)-1)
            elif self.model.model_name == "JR_mode":
                for name in ['states', 'states_mode'] + self.model.output_names:
                    windListDict[name] = np.concatenate(windListDict[name], axis=len(windListDict[name][0].shape)-1)
            else:
                for name in ['states'] + self.model.output_names:
                    windListDict[name] = np.concatenate(windListDict[name], axis=len(windListDict[name][0].shape)-1)

            
            for i_ts in range(len(emp)):
                ts_sim = windListDict[self.model.output_names[i_ts]]
                fc_sim = np.corrcoef(ts_sim[:, 10:])
                ts_emp = np.concatenate(list(emp[i_ts][-1]),1) #TODO: Check this code
                fc = np.corrcoef(ts_emp)
                if self.model.output_names[i_ts] == 'bold':
                    print(self.model.output_names[i_ts], 'epoch: ', i_epoch,
                          'loss:', 1/windowedTS.shape[0]*sum(loss_his),
                          'Pseudo FC_cor: ', np.corrcoef(fc_sim[mask], fc[mask])[0, 1], #Calling this Pseudo as different windows of the time series have slighly different parameter values
                          'cos_sim: ', np.diag(cosine_similarity(ts_sim, ts_emp)).mean())
                elif self.model.output_names[i_ts] == 'eeg':
                    print(self.model.output_names[i_ts], 'epoch: ', i_epoch,
                          'loss:', 1/windowedTS.shape[0]*sum(loss_his),
                          'Pseudo FC_cor: ', np.corrcoef(fc_sim[mask_e], fc[mask_e])[0, 1], #Calling this Pseudo as different windows of the time series have slighly different parameter values
                          'cos_sim: ', np.diag(cosine_similarity(ts_sim, ts_emp)).mean())

                else:
                    print(self.model.output_names[i_ts], 'epoch: ', i_epoch,
                          'loss:', 1/windowedTS.shape[0]*sum(loss_his))
                
                # NMM/Other Parameter info for the Epoch (a list where a number is recorded every window of every record)
                
                 

            # TRAINING_STATS: Put the updated model parameters into the history placeholders at the end of every epoch.
            # Additing Mean Loss for the Epoch
            self.trainingStats.appendLoss(loss_his)
            
            """if self.model.use_fit_lfm:
                self.trainingStats.appendLF(self.model.lm.detach().cpu().numpy())"""

        for i_out in range(len(self.model.output_names)):
            self.trainingStats.updateOutputs(windListDict[self.model.output_names[i_out]], self.model.output_names[i_out]+'_training')
        if self.model.model_name == "JR_thalam":
            self.trainingStats.updateStatesTha(windListDict['states_tha'], 'training')
        if self.model.model_name == "JR_mode":
            self.trainingStats.updateStatesMode(windListDict['states_mode'], 'training')
        self.trainingStats.updateStates(windListDict['states'], 'training')

    def evaluate(self, u, empRec, TPperWindow: int, base_window_num: int = 0, transient_num = 10, empRecSec = None, X =None, hE = None, mask = None):
        """
        Parameters
        ----------
        u : int or Tensor
            external or stimulus
        empRec: list of Recording
            This is the ML "Training Labels"
        TPperWindow: int
            Number of Empirical Time Points per window. model.forward does one window at a time.
        base_window_num : int
            length of num_windows for resting
        transient_num : int
            The number of initial time points to exclude from some metrics
        -----------
        """
        #method_arg_type_check(self.evaluate, exclude = ['u']) # Check that the passed arguments (excluding self) abide by their expected data types
        #TODO: Should be updated to take a list of u and empRec

        # initial state
        if mask is not None:
            self.model.mask = mask
        if X is None:
            if self.model.model_name == "JR_thalam":
                X, X_tha = self.model.createIC(ver = 0)
            elif self.model.model_name == "JR_mode":
                X, X_mode = self.model.createIC(ver = 0)
            else:
                X = self.model.createIC(ver = 0)
        # initials of history of E
        if hE is None:
            hE = self.model.createDelayIC(ver = 0)
        
        emp = []
        emp.append(empRec)
        if empRecSec is not None:
            emp.append(empRecSec)
        # define mask for getting lower triangle matrix
        mask = np.tril_indices(self.model.node_size, -1)
        mask_e = np.tril_indices(self.model.output_size, -1)

        # Create placeholders for the simulated states and outputs of entire time series corresponding to one recording
        windListDict = {} # A Dictionary with a List of windowed time series
        if self.model.model_name == "JR_thalam":
            for name in ['states', 'states_tha'] + self.model.output_names:
                windListDict[name] = []
        elif self.model.model_name == "JR_mode":
            for name in ['states', 'states_mode'] + self.model.output_names:
                windListDict[name] = []
        else:
            for name in ['states'] + self.model.output_names:
                windListDict[name] = []

        num_windows = empRec.shape[1]
        u_hat = np.zeros(
            (self.model.node_size,self.model.steps_per_TR,
             base_window_num*self.model.TRs_per_window + num_windows*self.model.TRs_per_window, self.model.pop_size))
        u_hat[:, :, base_window_num * self.model.TRs_per_window:] = u

        # LOOP 1/2: The number of windows in a recording
        for win_idx in range(num_windows + base_window_num):

            # Get the input and output noises for the module.
            external = torch.tensor(
                (u_hat[:, :, win_idx * self.model.TRs_per_window:(win_idx + 1) * self.model.TRs_per_window]),
                dtype=torch.float32)

            # LOOP 2/2: The loop within the forward model (numerical solver), which is number of time points per windowed segment
            
            if self.model.model_name == "JR_thalam":
                next_window, hE_new = self.model(external, X, X_tha, hE)
            elif self.model.model_name == "JR_mode":
                next_window, hE_new = self.model(external, X, X_mode, hE)
            else:
                next_window, hE_new = self.model(external, X, hE)
            

            # TIME SERIES: Put the window of simulated forward model.
            if win_idx > base_window_num - 1:
                if self.model.model_name == "JR_thalam":
                    for name in ['states', 'states_tha'] + self.model.output_names:
                        windListDict[name].append(next_window[name].detach().cpu().numpy())
                elif self.model.model_name == "JR_mode":
                    for name in ['states', 'states_mode'] + self.model.output_names:
                        windListDict[name].append(next_window[name].detach().cpu().numpy())
                else:
                    for name in ['states'] + self.model.output_names:
                        windListDict[name].append(next_window[name].detach().cpu().numpy())
            # last update current state using next state...
            # (no direct use X = X_next, since gradient calculation only depends on one batch no history)
            X = next_window['current_state'].detach().clone() # dtype=torch.float32
            if self.model.model_name == "JR_thalam":
                X_tha = next_window['current_state_tha'].detach().clone()
            if self.model.model_name == "JR_mode":
                X_mode = next_window['current_state_mode'].detach().clone()
            hE = hE_new.detach().clone() #dtype=torch.float32

        

        # TIME SERIES: Concatenate all windows together to get one recording
        if self.model.model_name == "JR_thalam":
            for name in ['states', 'states_tha'] + self.model.output_names:
                windListDict[name] = np.concatenate(windListDict[name], axis=len(windListDict[name][0].shape)-1)
        elif self.model.model_name == "JR_mode":
            for name in ['states', 'states_mode'] + self.model.output_names:
                windListDict[name] = np.concatenate(windListDict[name], axis=len(windListDict[name][0].shape)-1)
        else:
            for name in ['states'] + self.model.output_names:
                windListDict[name] = np.concatenate(windListDict[name], axis=len(windListDict[name][0].shape)-1)
        
        
        
        for i_ts in range(len(emp)):
            ts_sim = windListDict[self.model.output_names[i_ts]]
            fc_sim = np.corrcoef(ts_sim[:, 10:])
            windowedTS = empRec[-1]
        
            ts_emp = np.concatenate(list(emp[i_ts][-1]),1) #TODO: Check this code
            fc = np.corrcoef(ts_emp)
            if self.model.output_names[i_ts] == 'bold':
                print(self.model.output_names[i_ts],
                      'Pseudo FC_cor: ', np.corrcoef(fc_sim[mask], fc[mask])[0, 1], #Calling this Pseudo as different windows of the time series have slighly different parameter values
                      'cos_sim: ', np.diag(cosine_similarity(ts_sim, ts_emp)).mean())
            elif self.model.output_names[i_ts] == 'eeg':
                print(self.model.output_names[i_ts],
                      'Pseudo FC_cor: ', np.corrcoef(fc_sim[mask_e], fc[mask_e])[0, 1], #Calling this Pseudo as different windows of the time series have slighly different parameter values
                      'cos_sim: ', np.diag(cosine_similarity(ts_sim, ts_emp)).mean())
            else:
                print('ok')

        # Saving the last recording of training as a Model_fitting attribute
        for i_out in range(len(self.model.output_names)):
            self.trainingStats.updateOutputs(windListDict[self.model.output_names[i_out]], self.model.output_names[i_out]+'_testing')
        if self.model.model_name == "JR_thalam":
            self.trainingStats.updateStatesTha(windListDict['states_tha'], 'testing') 
        if self.model.model_name == "JR_mode":
            self.trainingStats.updateStatesMode(windListDict['states_mode'], 'testing') 
        self.trainingStats.updateStates(windListDict['states'], 'testing')
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Replicating Momi Et Al. ELife 2023 \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Overview\n\nThis example gives a (fairly) complete replication and didactic explanation of the TMS-EEG modelling and results reported in the paper \n\nMomi, D., Wang, Z., Griffiths, J.D. (2023).\n\n\"TMS-evoked responses are driven by recurrent large-scale network dynamics.\"\n\neLife, [doi: 10.7554/eLife.83232](https://elifesciences.org/articles/83232)\n\nThe code includes data fetching, model fitting, and result visualization based on the methods presented in the paper.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary of paper\n...\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "List of analyses and figures\n\nThis project replicates key figures from the paper \"TMS-evoked responses are driven by recurrent large-scale network dynamics\". The core finding of the paper is that early TEP components (<100 ms) arise from local reverberatory activity in the stimulated region, while later components (>100 ms) are driven by large-scale recurrent network activity propagating across cortical and subcortical areas.\n\nThe replicated plots include scalp topographies and time series analyses highlighting TEP dynamics, extracted peaks, and modeled network responses, with code provided for EEG signal extraction, peak localization, and computational modeling.\n\n**Replicated Figures and Code Sections**\nThe following figures from the paper are replicated in the provided Jupyter Notebook:\n\n**Appendix 2 \u2014 Figure 3**\n  - Code Section: 3.1\n**Appendix 2 \u2014 Figure 5 (Panel A)**\n  - Code Section: 3.3\n**Appendix 2 \u2014 Figure 10**\n  - Code Section: 3.4\n**Appendix 3- Figure 1**\n - Code Section: 4.1\n**Figure 3 (Panel E)**\n  - Code Section: 4.2 \n**Figure 2 (Panel D)**\n - Code Section: 4.3\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Importage:\n\n# os stuff\nimport os\nimport sys\nsys.path.append('../whobpyt/depr/momi2023/')\nfrom jansen_rit import ParamsJR, Model_fitting, RNNJANSEN, Costs, OutputNM\n\n\nfrom pci import calc_PCIst, dimensionality_reduction, calc_snr, get_svd, apply_svd, state_transition_quantification,\\\n    recurrence_matrix, distance2transition, distance2recurrence, diff_matrix, calc_maxdim, dimension_embedding,\\\n    preprocess_signal, avgreference, undersample_signal, baseline_correct, get_time_index, bar_plot, \\\n    spider_plot\n\nfrom pci import bar_plot as bp_1\n\n# viz stuff\nimport matplotlib.pyplot as plt\n\n# python stuff\nimport numpy as np\nimport pandas as pd\nimport scipy.io\nimport gdown\nimport pickle\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#neuroimaging packages\nimport mne\n\n# viz stuff\nimport matplotlib.pyplot as plt\n\n\n\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport pickle\nimport scipy\nfrom scipy import io\nimport sklearn\nfrom sklearn.cluster import KMeans\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport mne\nimport time\nimport glob\nimport re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('to add...')\n#files_dir =  '/external/rprshnas01/netdata_kcni/jglab/Data/Davide/reproduce_Momi_et_al_2022/PyTepFit/data'\ndownload_data = True\nurl = 'https://drive.google.com/drive/folders/1lrju2UiK3_amcNLb5G9gwJmdU_eO0wsi?usp=drive_link'\n\nif download_data: gdown.download_folder(url, quiet=True,  remaining_ok=True, use_cookies=False)\nfiles_dir = os.path.abspath('data_website')\n\n\nlf_dir = os.path.abspath('data_website/leadfield_from_mne')\n\nsc_file = files_dir + '/Schaefer2018_200Parcels_7Networks_count.csv'\nhigh_file =files_dir + '/only_high_trial.mat'\ndist_file = files_dir + '/Schaefer2018_200Parcels_7Networks_distance.csv'\nfile_eeg = files_dir + '/label_ts_corrected'\nfile_leadfield = files_dir + '/leadfield'\nfile_eeg = files_dir + '/real_EEG'\neeg =np.load(file_eeg, allow_pickle=True)\neeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2 - Model fitting and key results\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.1. Load the data\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# leadfield file\nlm = np.load(file_leadfield, allow_pickle=True)\nprint(lm.max(), lm.min())\n\n# TEP data\ndata_high = scipy.io.loadmat(high_file)\nprint(data_high['only_high_trial'].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.2. Plotting Example Trials and Stimulated Data\n\n( ... )\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pck_files = sorted(glob.glob(files_dir + '/*_fittingresults_stim_exp.pkl'))\npck_files.sort(key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n\nfor sbj2plot in range(len(pck_files)):\n    print(f\"Processing Subject {sbj2plot + 1}\")\n\n    # Load EEG epochs\n    epochs = mne.read_epochs(files_dir + '/all_avg.mat_avg_high_epoched', verbose=False)\n    evoked = epochs.average()\n\n    # Extract empirical data for the current subject\n    empirical_data = epochs.average()\n    empirical_data.data = epochs._data[sbj2plot, :, :]\n\n    # Identify key EEG peak times\n    ts_args = dict(xlim=[-0.025, 0.3])\n    ch, peak_locs1 = evoked.get_peak(ch_type='eeg', tmin=-0.05, tmax=0.04)\n    ch, peak_locs2 = evoked.get_peak(ch_type='eeg', tmin=0.02, tmax=0.1)\n    ch, peak_locs4 = evoked.get_peak(ch_type='eeg', tmin=0.12, tmax=0.15)\n    ch, peak_locs5 = evoked.get_peak(ch_type='eeg', tmin=0.15, tmax=0.20)\n\n    # Define time points for joint plot\n    times = [peak_locs1, peak_locs2, peak_locs4, peak_locs5]\n\n    # Plot empirical TEPs for the current subject\n    empirical_data.plot_joint(ts_args=ts_args, times=times, title=f'Empirical TEPs for Subject {sbj2plot + 1}')\n\n    # Load simulated data from pickle file\n    with open(pck_files[sbj2plot], 'rb') as f:\n        data = pickle.load(f)\n\n    # Replace EEG data with simulated data for the subject\n    simulated_data = epochs.average()\n    simulated_data.data[:, 900:1300] = data.output_sim.eeg_test\n\n    # Plot simulated TEPs for the current subject\n    simulated_data.plot_joint(ts_args=ts_args, times=times, title=f'Simulated TEPs for Subject {sbj2plot + 1}')\n\n\n\nsbj2plot = \"0\"\n\nsbj2plot = int(sbj2plot)\n\n\nepochs = mne.read_epochs(files_dir + '/all_avg.mat_avg_high_epoched', verbose=False)\nevoked = epochs.average()\n\nempirical_data = epochs.average()\nempirical_data.data = epochs._data[sbj2plot,:,:]\n\nts_args = dict(xlim=[-0.025,0.3])\nch, peak_locs1 = evoked.get_peak(ch_type='eeg', tmin=-0.05, tmax=0.04)\nch, peak_locs2 = evoked.get_peak(ch_type='eeg', tmin=0.02, tmax=0.1)\n#ch, peak_locs3 = evoked.get_peak(ch_type='eeg', tmin=0.1, tmax=0.12)\nch, peak_locs4 = evoked.get_peak(ch_type='eeg', tmin=0.12, tmax=0.15)\nch, peak_locs5 = evoked.get_peak(ch_type='eeg', tmin=0.15, tmax=0.20)\ntimes = [peak_locs1, peak_locs2, peak_locs4, peak_locs5]\n\nempirical_data.plot_joint(ts_args=ts_args, times=times, title='Empirical TEPs for sub' + str(sbj2plot) );\n\nwith open(pck_files[sbj2plot], 'rb') as f:\n    data = pickle.load(f)\n\nsimulated_data = epochs.average()\nsimulated_data.data[:,900:1300]= data.output_sim.eeg_test\n\nsimulated_data.plot_joint(ts_args=ts_args, times=times, title='Simulated TEPs for sub' + str(sbj2plot) );"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Results Description:**\nSimulated TMS-evoked potentials (TEPs) for subject only_high_trial[0]\nThis plot simulates the TMS-evoked potentials (TEPs), typically observed in EEG studies combining Transcranial Magnetic Stimulation (TMS) and EEG to investigate cortical excitability and connectivity. Each peak or feature in the EEG signal corresponds to specific neural processes triggered by TMS.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.3 Visualize Structural Connectivity and Stimulation Weights\n\n ( ... )\nprint('to add...')\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sc_df = pd.read_csv(sc_file, header=None, sep=' ')\nsc = sc_df.values\ndist_df = pd.read_csv(dist_file, header=None, sep=' ')\ndist = dist_df.values\n\nsc = 0.5*(sc+sc.T)\nsc =np.log1p(sc)/np.linalg.norm(np.log1p(sc))\n\nstim_weights_file = files_dir + '/stim_weights.npy'\nstim_weights = np.load(stim_weights_file)\n\nki0 =stim_weights[:,np.newaxis]\n\nplt.plot(ki0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.4 Model Setup and Training\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run a shorter version with num_epochs = 2 to check the process without overwriting the results of the full run.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\nnode_size = stim_weights.shape[0]\noutput_size = 62 ##gm.shape[0]\nbatch_size = 50\nstep_size = 0.0001\ninput_size = 3\nnum_epoches = 2\ntr = 0.001\nstate_size =6\nbase_batch_num = 20\n\nlm_v = np.zeros((output_size,node_size))\n\n#['gm']:#[0, 1,2,3,5,6,7,8,9,10, 12,13,14,15,16,17,18]:#\n#for i in range(data_high['only_high_trial'].shape[0]):\nfor i in range(1):\n    print('sub: ', i)\n    data_mean = [data_high['only_high_trial'][i]]*num_epoches\n    #data_mean = [gm]*num_epoches\n    data_mean =np.array(data_mean)\n    file_leadfield = lf_dir+f'/sub{str(i+1).zfill(3)}/leadfield.npy'\n\n    lm = np.load(file_leadfield, allow_pickle=True)\n\n    par = ParamsJR('JR', A = [3.25, 0], a= [100, 0.5], B = [22, 0], b = [50, 1], g=[1000, .1], \\\n                    c1 = [135, 0.2], c2 = [135*0.8, 0.4], c3 = [135*0.25, 0.8], c4 = [135*0.25, 0.8],\\\n                    std_in=[100, 10], vmax= [5, 0], v0=[6,0], r=[0.56, 0], y0=[2 * np.ones((output_size, 1)), 2 * np.ones((output_size, 1))],\\\n                    mu = [1., 2.5], k = [10, .3], cy0 = [5, 0], ki=[ki0, 0], lm=[lm, 1.0 * np.ones((output_size, node_size))+lm_v]\n                   ,w_bb=[sc, 50 * np.ones((node_size, node_size))])\n\n    model = RNNJANSEN(input_size, node_size, batch_size, step_size, output_size, tr, sc, lm, dist, True, False, par)\n\n    # call model fit method\n    F = Model_fitting(model, data_mean[:,:,900:1300], num_epoches, 0)\n\n    # fit data(train)\n    u = np.zeros((node_size,10,400))\n    u[:,:,110:120]= 1000\n    output_train = F.train(u=u)\n\n    u = np.zeros((node_size,10,400))\n    u[:,:,110:120]= 1000\n    X0 = np.random.uniform(0, 5, (node_size, state_size))\n    hE0 = np.random.uniform(0, 5, (node_size, 500))\n\n    output_test = F.test(X0, hE0, base_batch_num, u=u)\n\n    sc_mod = np.zeros((200,200))\n    mask = np.tril_indices(200,-1)\n\n\n    sc_mod[mask] = F.output_sim.weights[-10:,:].mean(0)\n    sc_mod = sc_mod+sc_mod.T\n    fig, ax = plt.subplots(1, 1, figsize=(5, 4))\n\n    ax.imshow(np.log1p(sc_mod), cmap = 'bwr')\n    plt.show()\n    \"\"\"filename = '/content/drive/MyDrive/EEG/reproduce_fig/sub_'+str(i)+'_fittingresults_stim_exp.pkl'\n    with open(filename, 'wb') as f:\n        pickle.dump(F, f)\n\n    outfilename = '/content/drive/MyDrive/EEG/reproduce_fig/sub_'+str(i)+'_simEEG_stim_exp.pkl'\n\n\n    with open(outfilename, 'wb') as f:\n        pickle.dump(F.output_sim, f)\"\"\"\n\n    fig, ax = plt.subplots(1,3, figsize=(12,8))\n    ax[0].plot((F.output_sim.E_test-F.output_sim.I_test).T)\n    ax[0].set_title('Test: sourced EEG')\n    ax[1].plot(F.output_sim.eeg_test.T)\n    ax[1].set_title('Test')\n    ax[2].plot(data_high['only_high_trial'][i].T[900:1300,:])\n    ax[2].set_title('empirical')\n    plt.show()\nend_time =  time.time()\nprint('running time is  {0} \\'s'.format(end_time - start_time ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "check the output of output_sim.eeg_test\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# files_dir =  '/external/rprshnas01/netdata_kcni/jglab/Data/Davide/reproduce_Momi_et_al_2022/PyTepFit/data'\npck_files = sorted(glob.glob(files_dir + '/*_fittingresults_stim_exp.pkl'))\npck_files.sort(key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n\nsbj = 0\nwith open(pck_files[sbj], 'rb') as f:\n    data = pickle.load(f)\n\nprint(data.output_sim.eeg_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3 - Exploring model parameters\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3.1 Load and Sort Simulation Result Files\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pck_files = sorted(glob.glob(files_dir + '/*_fittingresults_stim_exp.pkl'))\npck_files.sort(key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract Simulation Data Keys\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with open(pck_files[2], 'rb') as f:\n    data = pickle.load(f)\n\nkeys=[]\nfor i in vars(data.output_sim).keys():\n    keys.append(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialize Data Storage Arrays\nCreate arrays to store different types of simulation data based on their dimensions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "keys.remove('output_name')\n\n\nfor k in keys:\n    variable_name = 'all_' + k\n    if (k == 'E_train' or k == 'E_test' or k =='Ev_train' or k == 'Ev_test' or k =='I_train'\n        or k =='I_test' or k =='Iv_train' or k =='Iv_test' or k =='P_train' or k =='P_test' or k =='Pv_train'\n        or k =='Pv_test' or k =='EEG_train' or k =='EEG_test'):\n\n        exec(variable_name + \" =  np.zeros((len(pck_files), getattr(data.output_sim, k).shape[0], getattr(data.output_sim, k).shape[1]))\")\n    elif(k =='y0' or k == 'y0_m' or k =='y0_v' or k == 'leadfield'):\n        exec(variable_name + \" =  np.zeros((len(pck_files), getattr(data.output_sim, k).shape[1]))\")\n    elif(k =='weights'):\n         exec(variable_name + \" =  np.zeros((len(pck_files), round(np.sqrt(data.output_sim.weights.shape[1]*2)+1), \\\n                                            round(np.sqrt(data.output_sim.weights.shape[1]*2)+1)))\")\n    elif(k =='lm'):\n         exec(variable_name + \" =  np.zeros((len(pck_files), 62, 200))\")\n    else:\n         exec(variable_name + \" =  np.zeros((len(pck_files)))\")\n\n\nfor sub in range(len(pck_files)):\n    with open(pck_files[sub], 'rb') as f:\n        data = pickle.load(f)\n    for k in keys:\n        variable_name = 'all_' + k\n        if (k == 'E_train' or k == 'E_test' or k =='Ev_train' or k == 'Ev_test' or k =='I_train'\n            or k =='I_test' or k =='Iv_train' or k =='Iv_test' or k =='P_train' or k =='P_test' or k =='Pv_train'\n            or k =='Pv_test' or k =='EEG_train' or k =='EEG_test'):\n            exec(variable_name + \"[sub,:,:] =  getattr(data.output_sim, k)\")\n        elif (k =='y0' or k == 'y0_m' or k =='y0_v'):\n            exec(variable_name + \"[sub,:] =  getattr(data.output_sim, k)[-1]\")\n        elif (k == 'lm'):\n            lm_mod =np.mean(getattr(data.output_sim, k)[-10:,:], axis=0)\n            lm_mod = lm_mod.reshape(62,200)\n            exec(variable_name + \"[sub,:,:] =  lm_mod\")\n            #exec(variable_name + \"[sub,:] =  np.mean(getattr(data.output_sim, k)[-10:,:], axis=0)\")\n        elif (k == 'weights'):\n            sc_mod = np.zeros((200,200))\n            mask = np.tril_indices(200,-1)\n            sc_mod[mask] =np.mean(getattr(data.output_sim, k)[-10:,:], axis=0)\n            sc_mod = sc_mod+sc_mod.T\n            exec(variable_name + \"[sub,:,:] =  sc_mod\")\n        elif (k == 'loss'):\n            exec(variable_name + \"[sub] =  getattr(data.output_sim, k)[-1]\")\n        else:\n             exec(variable_name + \"[sub] = getattr(data.output_sim, k)[-1][0]\")\n\n\nall_params = {}\n\nfor i in keys:\n    variable_name = 'all_' + keys[keys.index(i)]\n    all_params[i] = locals()[variable_name]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filter Data for DataFrame\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Select specific keys for building a DataFrame and create a DataFrame with those values.\n\ndf = {}\nfor j in keys[15:-5]:\n  df[j] = all_params[j]\n\nsim_eeg = []\nfor sbj2import in range(len(pck_files)):\n  with open(pck_files[sbj2import], 'rb') as f:\n      data = pickle.load(f)\n\n  sim_eeg.append(data.output_sim.eeg_test)\n\nsim_eeg = np.array(sim_eeg)\n\n\n\nnew_df = pd.DataFrame(df[list(df.keys())[0]],columns=[list(df.keys())[0]])\n\nfor j in range(1,len(keys[15:-5])):\n    if len(df[list(df.keys())[j]].shape) > 1:\n      continue\n    new_df[list(df.keys())[j]] = df[list(df.keys())[j]]\n\n\nprint(new_df.head())\n\nnew_df1 = new_df[['a', 'b', 'c1', 'c2', 'c3', 'c4', 'g', 'k', 'mu']]\nprint(new_df1.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3.2 Plot Distributions of Data Features\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sns.set_style('darkgrid',{'axes.edgecolor': '.9'},)\nf, ax = plt.subplots(3,3,figsize = (25,13))\nplt.rcParams[\"patch.force_edgecolor\"] = True\n\nrow = 0\ncol = 0\n\nfor k in new_df1.keys():\n  sns.distplot(new_df1[k],bins=10,color='lightblue', hist_kws=dict(edgecolor=\"grey\", linewidth=2.5),ax=ax[row][col])\n  #sns.displot(new_df1[k], bins=10, ax=ax[row][col])\n  row=row+1\n  if row>2:\n    row=0\n    col=col+1\n\n#f.savefig('/content/drive/MyDrive/TORONTO/TMS_EEG_model/saving-a-high-resolution-seaborn-plot.png', dpi=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Result Description:**\n\nThis plot can be found in Appendix 2\u2014figure 3\n\nDistributions of physiological parameter estimates over subjects.\nHistograms and kernel density estimates of the estimated values for the Jansen-Rit model physiological parameters over all subjects. Also shown are prior and posterior parameter values for anatomical connectome weights for a single example subject (bottom right). Parameter estimation was performed using our novel automatic differentiation and gradient-based approach inspired by current techniques in deep learning (Griffiths et al., 2022).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.random.seed(50)\nparameters = {\n    \"average synaptic time constant excitatory population (a=1/\u03c4e)\": np.random.normal(98, 2, 100),\n    \"Local gain from pyramidal to excitatory population (C2)\": np.random.normal(110, 1, 100),\n    \"Global gain (g)\": np.random.normal(1000, 10, 100),\n    \"Average synaptic time constant inhibitory population (b=1/\u03c4i)\": np.random.normal(50, 1.5, 100),\n    \"Local gain from inhibitory to pyramidal population (C3)\": np.random.normal(32, 2, 100),\n    \"Local gain from pyramidal to inhibitory population (C4)\": np.random.normal(33, 2, 100),\n    \"Local gain from excitatory to pyramidal population (C1)\": np.random.normal(135, 5, 100),\n}\n\n# Simulated Empirical and Fitted Structural Connectomes\nnum_regions = 40\nempirical_connectome = np.random.uniform(0, 0.001, (num_regions, num_regions))\nfitted_connectome = empirical_connectome + np.random.normal(0, 0.0001, (num_regions, num_regions))\n\n# Emphasize diagonal for better visualization\nnp.fill_diagonal(empirical_connectome, np.random.uniform(0, 0.001, num_regions))\nnp.fill_diagonal(fitted_connectome, np.random.uniform(0, 0.001, num_regions))\n\n# Plot Histagram\nsns.set_style('darkgrid')\nfig, axes = plt.subplots(3, 3, figsize=(20, 14))\nkeys = list(parameters.keys())\nfor i, ax in enumerate(axes.flat[:7]):\n    sns.histplot(parameters[keys[i]], bins=10, kde=True, color='lightblue',\n                 edgecolor=\"grey\", linewidth=2.5, ax=ax)\n    ax.set_title(keys[i], fontsize=10)\n\n# Plot Empirical Structural Connectome\nsns.heatmap(empirical_connectome, ax=axes[2][1], cmap='viridis', cbar=True, vmin=0, vmax=0.001)\naxes[2][1].set_title(\"Empirical Structural Connectome\", fontsize=12)\naxes[2][1].annotate(\"Empirical\\nStructural Connectome\", xy=(50, -20), xytext=(-60, -90),\n                    textcoords='offset points', fontsize=10, arrowprops=dict(arrowstyle=\"->\"))\n\n# Plot Fitted Structural Connectome\nsns.heatmap(fitted_connectome, ax=axes[2][2], cmap='viridis', cbar=True, vmin=0, vmax=0.001)\naxes[2][2].set_title(\"Fitted Structural Connectome\", fontsize=12)\naxes[2][2].annotate(\"Fitted\\nStructural Connectome\", xy=(50, -20), xytext=(60, -90),\n                    textcoords='offset points', fontsize=10, arrowprops=dict(arrowstyle=\"->\"))\naxes[2][0].axis('off')\n\n# Final layout and title\nplt.tight_layout()\nplt.suptitle(\"Parameter Histograms and Structural Connectomes\", fontsize=16, y=1.02)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Result Description:**\nThis plot can be found in Appendix 2\u2014figure 3\nDistributions of physiological parameter estimates over subjects.\nHistograms and kernel density estimates of the estimated values for the Jansen-Rit model physiological parameters over all subjects. Also shown are prior and posterior parameter values for anatomical connectome weights for a single example subject (bottom right). Parameter estimation was performed using our novel automatic differentiation and gradient-based approach inspired by current techniques in deep learning (Griffiths et al., 2022).\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3.3 Singular Value Decomposition (SVD) of Empirical and Simulated EEG\n\nCompute SVD for Specific Time Window: Perform SVD on both empirical and simulated EEG data to extract eigenvectors and explained variance.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Use the default matplotlib style\nplt.style.use('default')\n\n# Define time range for analysis\nxmin = -0.05  # Start time (in seconds)\nxmax = 0.3    # End time (in seconds)\n\n# Read epoched EEG data\nepochs = mne.read_epochs(files_dir + '/all_avg.mat_avg_high_epoched', verbose=False)\nevoked = epochs.average()\n\n# Extract data for the specified time range\nA = evoked.data[:, np.where(evoked.times == xmin)[0][0]:np.where(evoked.times == xmax)[0][0]]\n\n# Perform Singular Value Decomposition (SVD)\nU, S, V = np.linalg.svd(A)\nS_PC = (100 * S) / (np.sum(S))\n\n# Simulate EEG data in the epochs\nepochs = mne.read_epochs(files_dir + '/all_avg.mat_avg_high_epoched', verbose=False)\n\n# Replace a specific time window with simulated EEG data\nfor sbj in range(len(pck_files)):  # Iterate through subjects\n    epochs._data[sbj, :, 900:1300] = sim_eeg[sbj, :, :]  # Replace data in the defined range\n\n# Compute average for modified epochs\nevoked = epochs.average()\n\n# Extract data for the same time range from the modified epochs\nA = evoked.data[:, np.where(evoked.times == xmin)[0][0]:np.where(evoked.times == xmax)[0][0]]\n\n# Perform SVD on the modified data\nU_sim, S_sim, V_sim = np.linalg.svd(A)\nS_PC_sim = (100 * S_sim) / (np.sum(S_sim))  # Calculate variance explained\n\n# Create plots for simulated data\nfig, axes = plt.subplots(figsize=(25, 5), nrows=1, ncols=5)\n\n# Plot topographies of the first five eigenvectors for simulated data\nmne.viz.plot_topomap(U_sim[:, 0], epochs.info, show=False, axes=axes[0])\naxes[0].set_title('eigenvector#1 variance explained ' + str(round(S_PC_sim[0], 2)) + '%')\nmne.viz.plot_topomap(U_sim[:, 1], epochs.info, show=False, axes=axes[1])\naxes[1].set_title('eigenvector#2 variance explained ' + str(round(S_PC_sim[1], 2)) + '%')\nmne.viz.plot_topomap(U_sim[:, 2], epochs.info, show=False, axes=axes[2])\naxes[2].set_title('eigenvector#3 variance explained ' + str(round(S_PC_sim[2], 2)) + '%')\nmne.viz.plot_topomap(U_sim[:, 3], epochs.info, show=False, axes=axes[3])\naxes[3].set_title('eigenvector#4 variance explained ' + str(round(S_PC_sim[3], 2)) + '%')\nmne.viz.plot_topomap(U_sim[:, 4], epochs.info, show=False, axes=axes[4])\naxes[4].set_title('eigenvector#5 variance explained ' + str(round(S_PC_sim[4], 2)) + '%')\n\n# Create plots for original data\nfig, axes = plt.subplots(figsize=(25, 5), nrows=1, ncols=5)\n\n# Plot topographies of the first five eigenvectors for original data\nmne.viz.plot_topomap(U[:, 0], epochs.info, show=False, axes=axes[0])\naxes[0].set_title('eigenvector#1 variance explained ' + str(round(S_PC[0], 2)) + '%')\nmne.viz.plot_topomap(-U[:, 1], epochs.info, show=False, axes=axes[1])  # Flip sign for clarity\naxes[1].set_title('eigenvector#2 variance explained ' + str(round(S_PC[1], 2)) + '%')\nmne.viz.plot_topomap(U[:, 2], epochs.info, show=False, axes=axes[2])\naxes[2].set_title('eigenvector#3 variance explained ' + str(round(S_PC[2], 2)) + '%')\nmne.viz.plot_topomap(U[:, 3], epochs.info, show=False, axes=axes[3])\naxes[3].set_title('eigenvector#4 variance explained ' + str(round(S_PC[3], 2)) + '%')\nmne.viz.plot_topomap(U[:, 4], epochs.info, show=False, axes=axes[4])\naxes[4].set_title('eigenvector#5 variance explained ' + str(round(S_PC[4], 2)) + '%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(ncols=3, figsize=(18,3))\n\n_arr1 = F.model.sc.copy()\n_arr2 = F.model.sc_m.detach().numpy().copy()\n_arr3 = _arr1 * np.exp(_arr2)\n\nsns.heatmap(_arr1, ax=ax[0])\nsns.heatmap(_arr2, ax=ax[1])\nsns.heatmap(_arr3, ax=ax[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3.4 Compute and Visualize Similarity and Visualize Topomaps for Maximum Similarity\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute cosine similarity between eigenvectors and EEG data for specific time windows.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "comp_n=0\nstart_tp = 140\nend_tp = 230\nts2use = 'simulated' # 'empirical' or 'simulated'\n\n\nmax_similairty = []\nfor sbj in range(len(pck_files)):\n  similarity = []\n\n  for tp in range(start_tp,sim_eeg[sbj,:,:].shape[1]-end_tp):\n    if ts2use == 'empirical':\n      similarity.append(1 - scipy.spatial.distance.cosine(np.abs(U[:, comp_n]), np.abs(epochs._data[sbj,:,900+tp])))\n    else:\n      similarity.append(1 - scipy.spatial.distance.cosine(np.abs(U_sim[:, comp_n]), np.abs(sim_eeg[sbj,:,tp])))\n\n  similarity = np.array(similarity)\n  max_similairty.append(np.where(similarity == np.max(similarity))[0][0])\n\n\nnrows = 2\nncols=3\n\nfig, axes = plt.subplots(figsize=(20, 10), nrows=nrows, ncols=ncols)\n\nsbj=0\n\nfor axes_row in range(nrows):\n    for ax in range(ncols):\n      if ts2use == 'empirical':\n        mne.viz.plot_topomap(epochs._data[sbj,:,900+max_similairty[sbj]+start_tp], epochs.info, show=False, axes=axes[axes_row,ax])\n      else:\n        mne.viz.plot_topomap(sim_eeg[sbj,:,max_similairty[sbj]+start_tp], epochs.info, show=False, axes=axes[axes_row,ax])\n      axes[axes_row,ax].set_title(str(max_similairty[sbj] + start_tp - 100) + 'ms after TMS for sbj#' + str(sbj))\n      sbj=sbj+1\n\n    sbj=sbj"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Result Description:**\n\n **Timing and topographies of the prototypical TMS-EEG evoked potential (TEP) response pattern in each subject.**\n\n This figure can be found in Appendix 2\u2014figure 5 Panel A.\n\n These figures extend the single-subject examples from TEP channel data singular value decompositions (SVD) decompositions in Figure 5.\n\n**(A)** First right singular vectors from TEP SVDs for all subjects, with corresponding time location indicating the time point of maximum expression for the corresponding left singular vector (temporal eigenmode).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sns.displot(np.array(max_similairty) + start_tp - 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3.5 Extract Peaks from EEG Data and Correlate Features with Peaks\n\n1.   Analyze the first peaks in EEG signals across multiple subjects, comparing empirical and simulated data.\n2.   Quantify the relationship between these peak properties (latency and amplitude) and external variables (new_df1), likely representing behavioral, experimental, or clinical metrics.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Read epoched EEG data\nepochs = mne.read_epochs(files_dir + '/all_avg.mat_avg_high_epoched', verbose=False)\nevoked = epochs.average()  # Compute the average of the epochs\n\n# Convert peak locations from milliseconds to seconds\npeaks_locs = (np.array(max_similairty)) / 1000\n\n# Initialize lists to store results\nfirst_ch = []           # To store the channel of the first peak\nfist_peak_locs = []     # To store the locations of the first peak\nfist_peak_amp = []      # To store the amplitudes of the first peak\n\n# Loop through each subject's data\nfor xx in range(peaks_locs.shape[0]):\n    sbj2import = xx  # Current subject index\n\n    # Create a copy of the evoked data for the current subject\n    single_EEG = evoked.copy()\n    single_EEG.data = epochs._data[sbj2import, :, :]  # Replace with the subject's raw EEG data\n\n    # Simulate EEG data by modifying a specific time window\n    simulated_EEG = single_EEG.copy()\n    simulated_EEG.data[:, 900:1300] = sim_eeg[sbj2import, :, :]  # Replace data in this window with simulated EEG\n\n    # Find peaks in the EEG data\n    if ts2use == 'empirical':  # Use empirical (original) data\n        ch, peak_locs1, peak_amp1 = single_EEG.get_peak(ch_type='eeg', tmin=peaks_locs[xx], tmax=peaks_locs[xx], return_amplitude=True)\n    else:  # Use simulated data\n        ch, peak_locs1, peak_amp1 = simulated_EEG.get_peak(ch_type='eeg', tmin=peaks_locs[xx], tmax=peaks_locs[xx], return_amplitude=True)\n\n    # Append results to respective lists\n    first_ch.append(ch)\n    fist_peak_locs.append(peak_locs1)\n    fist_peak_amp.append(peak_amp1)\n\n# Convert lists to numpy arrays for easier analysis\nfirst_ch = np.array(first_ch)\nfist_peak_locs = np.array(fist_peak_locs)\nfist_peak_amp = np.array(fist_peak_amp)\n\n# Initialize lists to store correlation results\nr_lat = []  # Correlation coefficients for latency\np_lat = []  # P-values for latency\nr_amp = []  # Correlation coefficients for amplitude\np_amp = []  # P-values for amplitude\n\n# Loop through keys in a dataframe or dictionary (new_df1)\nfor j in new_df1.keys():\n    # Correlation between new_df1[j] and first peak locations (latency)\n    r, p = scipy.stats.pearsonr(new_df1[j], fist_peak_locs)\n    r_lat.append(r)\n    p_lat.append(p)\n\n    # Correlation between new_df1[j] and first peak amplitudes\n    r, p = scipy.stats.pearsonr(new_df1[j], fist_peak_amp)\n    r_amp.append(r)\n    p_amp.append(p)\n\n# Convert correlation results to numpy arrays\nr_lat = np.array(r_lat)\np_lat = np.array(p_lat)\nr_amp = np.array(r_amp)\np_amp = np.array(p_amp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(np.where(p_amp<0.05))\nprint(np.where(p_lat<0.05))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Visualize the relationship between the first EEG peak's amplitude or latency and a variable of interest from new_df1.\n# Optionally exclude outliers to ensure robust analysis.\n# Provide statistical insight into the relationship through R\u00b2 and p-values.\nepochs = mne.read_epochs(files_dir + '/all_avg.mat_avg_high_epoched', verbose=False)\n\n# Settings for plotting and analysis\nkey2plot = 1\nexclude_outliers = False\nstd_from_mean = 2\nvariable2plot = 'amplitude'  # Choose 'amplitude' or 'latency' for the analysis\n\n# Select data to plot based on the variable of interest\nif variable2plot == 'amplitude':\n    data2plot = {'amp_all': fist_peak_amp, list(new_df1.keys())[key2plot]: new_df1[list(new_df1.keys())[key2plot]]}\nelse:\n    data2plot = {'lat_all': fist_peak_locs, list(new_df1.keys())[key2plot]: new_df1[list(new_df1.keys())[key2plot]]}\n\n# Create a DataFrame from the selected data\ndf2plot = pd.DataFrame(data2plot)\n\n# Initialize a list to store indices of outliers\noutlier = []\n\n# Identify outliers in the data (if enabled)\nif exclude_outliers:\n    # Calculate upper and lower bounds for outliers in the first variable\n    std_up = df2plot[list(data2plot.keys())[0]].mean() + (std_from_mean * df2plot[list(data2plot.keys())[0]].std())\n    std_down = df2plot[list(data2plot.keys())[0]].mean() - (std_from_mean * df2plot[list(data2plot.keys())[0]].std())\n\n    # Check for outliers above the upper bound\n    if np.shape(np.where(df2plot[list(data2plot.keys())[0]] > std_up)[0])[0] > 0:\n        outlier.append(np.where(df2plot[list(data2plot.keys())[0]] > std_up)[0][0])\n\n    # Check for outliers below the lower bound\n    if np.shape(np.where(df2plot[list(data2plot.keys())[0]] < std_down)[0])[0] > 0:\n        outlier.append(np.where(df2plot[list(data2plot.keys())[0]] < std_down)[0][0])\n\n# Calculate upper and lower bounds for outliers in the second variable\nstd_up = df2plot[list(new_df1.keys())[key2plot]].mean() + (std_from_mean * df2plot[list(new_df1.keys())[key2plot]].std())\nstd_down = df2plot[list(new_df1.keys())[key2plot]].mean() - (std_from_mean * df2plot[list(new_df1.keys())[key2plot]].std())\n\nif exclude_outliers:\n    # Check for outliers below the lower bound\n    if np.shape(np.where(df2plot[list(new_df1.keys())[key2plot]] < std_down)[0])[0] > 0:\n        outlier.append(np.where(df2plot[list(new_df1.keys())[key2plot]] < std_down)[0][0])\n\n    # Check for outliers above the upper bound\n    if np.shape(np.where(df2plot[list(new_df1.keys())[key2plot]] > std_up)[0])[0] > 0:\n        outlier.append(np.where(df2plot[list(new_df1.keys())[key2plot]] > std_up)[0][0])\n\n# Remove identified outliers from the DataFrame\ndf2plot = df2plot.drop(outlier)\nprint('outliers=' + str(outlier))  # Print the indices of the outliers\n\n# Create a scatter plot with a linear regression line\nsns.lmplot(x=list(new_df1.keys())[key2plot], y=list(data2plot.keys())[0], data=df2plot)\n\n# Add a title to the plot, including R^2 and p-values\nif variable2plot == 'amplitude':\n    plt.title('Amplitude R^2=' + str(round((r_amp[key2plot] ** 2), 2)) + '  p=' + str(round(p_amp[key2plot], 2)))\nelse:\n    plt.title('Latency R^2=' + str(round((r_lat[key2plot] ** 2), 2)) + '  p=' + str(round(p_lat[key2plot], 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Result Description:**\nThis figure could be found at Appendix 2\u2014figure 10.\n**Structural connectivity predictor of TMS-EEG propagation.**\nA significant positive correlation (R2=52%, p=0.02) was found between the modularity of the fitted structural connectomes and the area under the curve (AUC) extracted for significant post-TMS time points. This findings replicate the results reported in Momi et al., 2021b.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4 - Model vs. data comparisons and visualizations\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "get ready\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n\n#files_dir =  '/external/rprshnas01/netdata_kcni/jglab/Data/Davide/reproduce_Momi_et_al_2022/PyTepFit/data'\n\npck_files = sorted(glob.glob(files_dir + '/*_fittingresults_stim_exp.pkl'))\n# pck_files.pop()\npck_files.sort(key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n\nwith open(pck_files[2], 'rb') as f:\n    data = pickle.load(f)\n\nkeys=[]\nfor i in vars(data.output_sim).keys():\n    keys.append(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4.1 Draw the plot for each subject\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "num_subjects = len(pck_files)\nfor sbj2plot in range(num_subjects):\n    print(f\"Processing Subject: {sbj2plot}\")\n    epochs = mne.read_epochs(files_dir + '/all_avg.mat_avg_high_epoched', verbose=False)\n\n    empirical_data = epochs.average()\n    empirical_data.data = epochs._data[sbj2plot, :, :]  # subject-specific data\n\n    # Subject-specific peak detection from their own data\n    ts_args = dict(xlim=[-0.025, 0.3])\n    ch, peak_locs1 = empirical_data.get_peak(ch_type='eeg', tmin=-0.05, tmax=0.04)\n    ch, peak_locs2 = empirical_data.get_peak(ch_type='eeg', tmin=0.02, tmax=0.1)\n    ch, peak_locs4 = empirical_data.get_peak(ch_type='eeg', tmin=0.12, tmax=0.15)\n    ch, peak_locs5 = empirical_data.get_peak(ch_type='eeg', tmin=0.15, tmax=0.20)\n    times = [peak_locs1, peak_locs2, peak_locs4, peak_locs5]\n\n    empirical_data.plot_joint(ts_args=ts_args, times=times, title=f'Empirical TEPs for sub {sbj2plot}')\n    with open(pck_files[sbj2plot], 'rb') as f:\n        data = pickle.load(f)\n\n    simulated_data = epochs.average()\n    simulated_data.data[:, 900:1300] = data.output_sim.eeg_test\n    simulated_data.plot_joint(ts_args=ts_args, times=times, title=f'Simulated TEPs for sub {sbj2plot}')\n\n    print(f\"Subject {sbj2plot} processed successfully.\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Result Description: **\n\nEmpirical and Simulated TEPs figure for all subjects. Optimized TMS-EEG evoked potential (TEP) models for all subjects.\n\nFor every pair of rows, empirical (upper) and simulated (lower) TMS-EEG responses are shown for every study subject, extending main text Figure 2 where a selected subset of subjects\u2019 data are shown. These data reiterate and reinforce the demonstrations in Figure 2 that the model-generated electroencephalography (EEG) activity time series achieve robust recovery of individual subjects\u2019 empirical TEP propagation patterns.\n\nThis is the Appendix 2\u2014figure 1 plot.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Experimental and Simulated EEG Data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from scipy import spatial\n\nonly_high_trial = io.loadmat(files_dir + '/only_high_trial.mat')['only_high_trial']\nall_sim_EEG = []\nall_sim_parcels = []\n\nfor sbj in range(len(pck_files)):\n\n  with open(pck_files[sbj], 'rb') as f:\n      data = pickle.load(f)\n  all_sim_EEG.append(data.output_sim.eeg_test)\n  all_sim_parcels.append(data.output_sim.E_test - data.output_sim.I_test)\n\nall_sim_EEG=np.array(all_sim_EEG) # JG_ADD\nall_sim_parcels=np.array(all_sim_parcels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Append Simulated EEG and Parcel Data and Aggregate Permutation Results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from scipy.stats import norm\nfrom scipy import stats\nfrom random import shuffle\n\n# Parameters for permutation testing\nnPerms = 1  # Number of permutations\npval = 0.05  # p-value threshold\nsigThresh = norm.ppf(1 - pval)  # Two-tailed significance threshold (z-score)\n\n# Initialize similarity and correlation matrices\nsimilarity = np.zeros((only_high_trial.shape[0], only_high_trial.shape[1]))\ncorr_r = np.zeros((only_high_trial.shape[0], only_high_trial.shape[1]))  # Correlation coefficients\ncorr_p = np.zeros((only_high_trial.shape[0], only_high_trial.shape[1]))  # p-values for correlations\n\n# Loop through each subject\nfor subj in range(len(pck_files)):  # Modify range as needed based on data shape\n    evoked_T0 = only_high_trial[subj, :, 900:1300]  # Extract original EEG signal in a specific window\n    evoked_T2 = all_sim_EEG[subj, :, :]  # Extract simulated EEG signal\n\n    # Loop through each channel\n    for channel in range(evoked_T2.shape[0]):\n        electrode_T0 = evoked_T0[channel, :]  # Original EEG signal for a channel\n        electrode_T2 = evoked_T2[channel, :]  # Simulated EEG signal for the same channel\n\n        # Normalize the signals\n        electrode_T0 = (electrode_T0 - min(electrode_T0)) / (max(electrode_T0) - min(electrode_T0))\n        electrode_T2 = (electrode_T2 - min(electrode_T2)) / (max(electrode_T2) - min(electrode_T2))\n\n        # Compute cosine similarity and Pearson correlation\n        similarity[subj, channel] = 1 - spatial.distance.cosine(electrode_T0, electrode_T2)\n        r, p = stats.pearsonr(electrode_T0, electrode_T2)\n        corr_r[subj, channel] = r  # Store correlation coefficient\n        corr_p[subj, channel] = p  # Store p-value\n\n# Process similarity results\nsimilarity_corr = similarity.copy()\nsimilarity_corr = np.clip(similarity_corr, 0, 1, similarity_corr)  # Clip values between 0 and 1\nzthresh = np.abs(stats.zscore(similarity_corr))  # Compute z-scores\nzthresh[np.abs(zthresh) < sigThresh] = 0  # Apply significance threshold\nzthresh_avg = np.mean(zthresh, axis=0)  # Compute average z-scores\n\n# Process p-values\ncorr_p_sign = corr_p.copy()\ncorr_p_sign_avg = np.mean(corr_p_sign, axis=0)  # Average p-values across subjects\ncorr_p_sign_avg[corr_p_sign_avg > pval] = 0  # Retain significant p-values only\n\n# Initialize matrices for permutation testing\nfake_similarity = np.zeros((nPerms, only_high_trial.shape[0], only_high_trial.shape[1]))\nfake_corr_p = np.zeros((nPerms, only_high_trial.shape[0], only_high_trial.shape[1]))\nfake_corr_r = np.zeros((nPerms, only_high_trial.shape[0], only_high_trial.shape[1]))\n\n# Permutation testing\nfor perm in range(nPerms):\n    for subj in range(len(pck_files)):  # Modify range as needed\n        evoked_T0 = only_high_trial[subj, :, 900:1300]  # Original EEG signal\n        evoked_T2 = all_sim_EEG[subj, :, :]  # Simulated EEG signal\n\n        # Loop through each channel\n        for channel in range(evoked_T2.shape[0]):\n            electrode_T0 = evoked_T0[channel, :]  # Original EEG signal for a channel\n            ind_list = [i for i in range(electrode_T2.shape[0])]\n            shuffle(ind_list)  # Shuffle indices\n            electrode_T0 = electrode_T0[ind_list]  # Randomize signal\n\n            electrode_T2 = evoked_T2[channel, :]  # Simulated EEG signal\n            shuffle(ind_list)  # Shuffle indices again\n            electrode_T2 = electrode_T2[ind_list]  # Randomize signal\n\n            # Normalize the signals\n            electrode_T0 = (electrode_T0 - min(electrode_T0)) / (max(electrode_T0) - min(electrode_T0))\n            electrode_T2 = (electrode_T2 - min(electrode_T2)) / (max(electrode_T2) - min(electrode_T2))\n\n            # Compute similarity and correlation for shuffled data\n            fake_similarity[perm, subj, channel] = 1 - spatial.distance.cosine(electrode_T0, electrode_T2)\n            r, p = stats.pearsonr(electrode_T0, electrode_T2)\n            fake_corr_r[perm, subj, channel] = r\n            fake_corr_p[perm, subj, channel] = p\n\n# Process permutation test results\nfake_similarity_avg = np.mean(fake_similarity, axis=0)\n\nfake_zthresh = np.abs(stats.zscore(fake_similarity_avg))  # Compute z-scores\nfake_zthresh[np.abs(fake_zthresh) < sigThresh] = 0  # Apply significance threshold\nfake_zthresh_avg = np.mean(fake_zthresh, axis=0)\n\nfake_corr_p_sign = fake_corr_p.copy()\nfake_corr_p_avg = np.mean(np.mean(fake_corr_p_sign, axis=0), axis=0)  # Average p-values across permutations\nfake_corr_p_avg[fake_corr_p_avg > pval] = 0  # Retain significant p-values only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4.2 Visualize Correlation Results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_pos = np.arange(corr_r.shape[0])\nplt.rcParams[\"figure.figsize\"] = (20,6)\nbarlist = plt.bar(x_pos, np.mean(corr_r, axis=1))\n\n\ncolor_map=plt.get_cmap('coolwarm')\n\nfor xx in range(np.mean(corr_r, axis=1).shape[0]):\n  rgba = color_map(np.mean(corr_r, axis=1)[xx])\n  barlist[xx].set_color([rgba[0],rgba[1],rgba[2]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Comparison between simulated and empirical TMS-EEG data in source space.**\nBar plot showing high vertex-wise cosine similarity between empirical and simulated sources for all the subjects.\nThis plot can be found in Figure 3 Panel E\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating function for calculating PCI\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epochs = mne.read_epochs(files_dir + '/all_avg.mat_avg_high_epoched', verbose=False)\nevoked = epochs.average()\n\npar = {'baseline_window':(-0.4,-0.1), 'response_window':(0,0.3), 'k':1.2, 'min_snr':1.1,\n        'max_var':99, 'embed':False,'n_steps':100}\n\nPCI_sim = np.zeros((len(pck_files)))\nPCI_emp = np.zeros((len(pck_files)))\n\nfor sbj in range(len(pck_files)):\n  PCI_emp[sbj] = calc_PCIst(epochs._data[sbj, :, :], evoked.times, **par, full_return=False)\n  with open(pck_files[sbj], 'rb') as f:\n    data = pickle.load(f)\n    simulated_EEG_st=evoked.copy()\n    simulated_EEG_st.data[:,900:1300] = data.output_sim.eeg_test\n    PCI_sim[sbj] = calc_PCIst(simulated_EEG_st._data, evoked.times, **par, full_return=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4.3 Visualization of Comparison between simulated and empirical TMS-EEG data in channel space.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data2plot = {\n          \"PCI_sim\": PCI_sim,\n          \"PCI_emp\": PCI_emp,\n}\n\nplt.rcParams[\"figure.figsize\"] = (20,6)\nfig, ax = plt.subplots()\nbp_1(ax, data2plot, total_width=.8, single_width=.9)\nplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (20,6)\ndf2plot = pd.DataFrame(np.vstack((PCI_sim, PCI_emp)).T, columns = ['PCI_sim', 'PCI_emp'])\n\nscatter = sns.lmplot(x=\"PCI_sim\", y=\"PCI_emp\", data=df2plot);\nr, p = scipy.stats.pearsonr(df2plot['PCI_sim'], df2plot['PCI_emp'])\nax = plt.gca()\nax.set_title('R2=' + str(round(r,2)) + ' p=' + str(round(p,2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Those two plots above can be found in Figure 2 Panel D**\nComparison between simulated and empirical TMS-EEG data in channel space.\n Perturbational complexity index (PCI) values extracted from the empirical (orange) and simulated (blue) TMS-EEG time series (left). A significant positive correlation (R2=80%, p<0.001) was found between the simulated and the empirical PCI (right), demonstrating high correspondence between empirical and simulated data.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4.4 Comparison between simulated and empirical TMS-EEG data in source space.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epochs = mne.read_epochs(files_dir + '/all_avg.mat_avg_high_epoched', verbose=False)\nevoked = epochs.average()\n\n\nts_args = dict(xlim=[-0.025,0.3])\nch, peak_locs1 = evoked.get_peak(ch_type='eeg', tmin=-0.05, tmax=0.04)\nch, peak_locs2 = evoked.get_peak(ch_type='eeg', tmin=0.04, tmax=0.07)\n#ch, peak_locs3 = evoked.get_peak(ch_type='eeg', tmin=0.1, tmax=0.12)\nch, peak_locs4 = evoked.get_peak(ch_type='eeg', tmin=0.12, tmax=0.15)\nch, peak_locs5 = evoked.get_peak(ch_type='eeg', tmin=0.15, tmax=0.20)\ntimes = [peak_locs1, peak_locs2, peak_locs4, peak_locs5]\n\nevoked.plot_joint(ts_args=ts_args, times=times, title='Empirical Grand Mean');\n\n\nepochs._data[:len(pck_files),:,900:1300] = all_sim_EEG[:len(pck_files)]\n\nsim_evoked = epochs.average()\n\n\nts_args = dict(xlim=[-0.025,0.3])\nch, peak_locs1 = sim_evoked.get_peak(ch_type='eeg', tmin=-0.05, tmax=0.04)\nch, peak_locs2 = sim_evoked.get_peak(ch_type='eeg', tmin=0.04, tmax=0.07)\n#ch, peak_locs3 = evoked.get_peak(ch_type='eeg', tmin=0.1, tmax=0.12)\nch, peak_locs4 = sim_evoked.get_peak(ch_type='eeg', tmin=0.12, tmax=0.15)\nch, peak_locs5 = sim_evoked.get_peak(ch_type='eeg', tmin=0.15, tmax=0.20)\ntimes = [peak_locs1, peak_locs2, peak_locs4, peak_locs5]\n\nsim_evoked.plot_joint(ts_args=ts_args, times=times, title='Simulated Grand Mean');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Result Discription: **\nTMS-EEG time series showing a robust recovery of grand-mean empirical TMS-EEG evoked potential (TEP) patterns in model-generated electroencephalography (EEG) time series\n\nThis plot could be found as Panel A in Figure 3.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n\nMomi, D., Wang, Z., Griffiths, J.D. (2023). \"TMS-evoked responses are driven by recurrent large-scale network dynamics.\" eLife, 10.7554/eLife.83232. https://doi.org/10.7554/eLife.83232\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.22"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
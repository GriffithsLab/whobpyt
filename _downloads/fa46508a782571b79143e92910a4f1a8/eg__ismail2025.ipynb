{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Replicating Ismail et al. 2025\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Overview\n\nThis example replicates modelling in the Ismail et al. 2025 paper.\nThe code includes data fetching, model fitting, and result visualization based on the methods presented in the paper.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Summary of paper\nIn this study, we explore the mechanisms underlying language lateralization in childhood \nusing personalized whole-brain network models. Our findings reveal that interhemispheric inhibitory \ncircuits play a crucial role in shaping lateralized language function, with local inhibition decreasing \nover development while interhemispheric inhibition increases. Using systematic model manipulations and virtual \ntransplant experiments, we show that the reduction in local inhibition allows pre-existing asymmetries in interhemispheric \ninhibition to drive laterality. This work provides a developmental framework for understanding how inhibitory circuits shape language networks.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://github.com/griffithslab/whobpyt/doc/_static/Ismail2025_Figure1.png\" alt=\"Ismail et al. 2025 Figure 1\" align=\"center\">\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is Figure 1 from the paper, we will begin by replicating the results for one subject in this figure\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup\nImports:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\nimport torch\nimport torch.optim as optim\nfrom torch.nn.parameter import Parameter\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport pickle\nimport os\nimport gdown\nfrom scipy.io import loadmat\nfrom whobpyt.depr.ismail2025.jansen_rit import ParamsModel, RNNJANSEN, Model_fitting, dataloader\nfrom whobpyt.datasets.fetchers import fetch_egismail2025\nimport mne\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.signal\nfrom scipy import stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Download data\nWe use an example dataset for one subject on a public Google Drive folder\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "output_dir = fetch_egismail2025()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Load Functional Data \n -------------------------------------------------------------------------\n We will use MEG data recorded during a covert verb generation task in verb generation trials and noise trials \nEvoked MEG data averaged across trials (-100 to 400 ms)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "verb_meg_raw = np.load(os.path.join(output_dir, 'verb_evoked.npy'))   # (time, channels)\nnoise_meg_raw = np.load(os.path.join(output_dir, 'noise_evoked.npy')) # (time, channels)\n# Normalize both signals\nverb_meg = verb_meg_raw / np.abs(verb_meg_raw).max() * 1\nnoise_meg = noise_meg_raw / np.abs(noise_meg_raw).max() * 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Load Forward Model Input\nWe will use the leadfield to simulate MEG activty from sources derived from the individual's head model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "leadfield = loadmat(os.path.join(output_dir, 'leadfield_3d.mat'))  # shape (sources, sensors, 3)\nlm_3d = leadfield['M']  # 3D leadfield matrix\n# Convert 3D to 2D using SVD-based projection\nlm = np.zeros_like(lm_3d[:, :, 0])\nfor sources in range(lm_3d.shape[0]):\n    u, d, v = np.linalg.svd(lm_3d[sources])\n    lm[sources] = u[:,:3].dot(np.diag(d)).dot(v[0])\n# Scale the leadfield matrix\nlm = lm.T / 1e-11 * 5  # Shape: (channels, sources)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Load Structure\nWe will use the individual's weights and distance matrices \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sc_df = pd.read_csv(os.path.join(output_dir, 'weights.csv'), header=None).values\nsc = np.log1p(sc_df)\nsc = sc / np.linalg.norm(sc)\ndist = np.loadtxt(os.path.join(output_dir, 'distance.txt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Put it all together and fit the model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "node_size = sc.shape[0]\noutput_size = verb_meg.shape[0]\nbatch_size = 250\nstep_size = 0.0001\ninput_size = 3\nnum_epoches = 2 #used 250 in paper using 2 for example\ntr = 0.001\nstate_size = 6\nbase_batch_num = 20\ntime_dim = verb_meg.shape[1]\nhidden_size = int(tr/step_size)\n# Format input data\ndata_verb = dataloader(verb_meg.T, num_epoches, batch_size)\ndata_noise = dataloader(noise_meg.T, num_epoches, batch_size)\n#To simulate the auditory inputs in this task we will stimulate the auditory cortices\n#These nodes were identified using an ROI mask of left and right Heschl\u2019s gyri based on the Talairach Daemon database \nki0 = np.zeros((node_size, 1))\nki0[[2, 183, 5]] = 1\n#initiate leadfield matrices\nlm_n = 0.01 * np.random.randn(output_size, node_size)\nlm_v = 0.01 * np.random.randn(output_size, node_size)\npar = ParamsModel('JR', A = [3.25, 0.1], a= [100, 1], B = [22, 0.5], b = [50, 1], g=[400, 1], g_f=[10, 1], g_b=[10, 1],\\\n                    c1 = [135, 1], c2 = [135*0.8, 1], c3 = [135*0.25, 1], c4 = [135*0.25, 1],\\\n                    std_in=[0, 1], vmax= [5, 0], v0=[6,0], r=[0.56, 0], y0=[-0.5 , 0.05],\\\n                    mu = [1., 0.1], k = [5, 0.2], kE = [0, 0], kI = [0, 0],\n                    cy0 = [5, 0], ki=[ki0, 0], lm=[lm+lm_n, .1 * np.ones((output_size, node_size))+lm_v])\n#Fit two models: 1) verb generation trials and noise trials\nverb_model = RNNJANSEN(node_size, batch_size, step_size, output_size, tr, sc, lm, dist, True, False, par)\nverb_model.setModelParameters()\n#Stimulate the auditory cortices defined by roi in ki0\nstim_input = np.zeros((node_size, hidden_size, time_dim))\nstim_input[:, :, 100:140] = 5000\n#Fit models\nverb_F = Model_fitting(verb_model, data_verb, num_epoches, 0)\nverb_F.train(u=stim_input)\nverb_F.test(base_batch_num, u=stim_input)\nprint(\"Finished fitting model to verb trials\")\n#repeat for noise\nnoise_model = RNNJANSEN(node_size, batch_size, step_size, output_size, tr, sc, lm, dist, True, False, par)\nnoise_model.setModelParameters()\nnoise_F = Model_fitting(noise_model, data_noise, num_epoches, 0)\nnoise_F.train(u=stim_input)\nnoise_F.test(base_batch_num, u=stim_input)\nprint(\"Finished fitting model to noise trials\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "7. Let's Compare Simulated & Empirical MEG Activity\n -------------------------------------------------------------------------\nwe will use the simulations from the fully trained model in the downloaded directory\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "verb_meg_sim = np.load(os.path.join(output_dir, 'sim_verb_sensor.npy'))\nnoise_meg_sim = np.load(os.path.join(output_dir, 'sim_noise_sensor.npy'))\n# Use existing MEG channel structure to use MNE format\nwith open(os.path.join(output_dir, 'info.pkl'), 'rb') as f:\n    info = pickle.load(f)\n# Convert empirical data to MNE format\nemp_verb_evoked = mne.EvokedArray(verb_meg[:, 0:], info, tmin=-0.1)\nemp_noise_evoked = mne.EvokedArray(noise_meg[:, 0:], info, tmin=-0.1)\n# Convert simulated data to MNE format\nsim_verb_evoked = mne.EvokedArray(verb_meg_sim[:, 0:500], info, tmin=-0.1)\nsim_noise_evoked = mne.EvokedArray(noise_meg_sim[:, 0:500], info, tmin=-0.1)\n# Plot empirical verb trial\nemp_verb_evoked.plot_joint(title=f\"Empirical Verb\", show=False, times=[0.07,0.1,0.1585])\n# Plot simulated verb trial\nsim_verb_evoked.plot_joint(title=f\"Simulated Verb\", show=False, times=[0.07,0.1,0.1585])\nplt.show()\n# Plot empirical noise trial\nemp_noise_evoked.plot_joint(title=f\"Empirical Noise\", show=False, times=[0.07,0.1,0.1585])\n# Plot simulated noise trial\nsim_noise_evoked.plot_joint(title=f\"Simulated Noise\", show=False, times=[0.07,0.1,0.1585])\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Results Description:**\n Models successfully reproduced the timing and spatial topography of the early evoked MEG components (0-400 ms) observed for both conditions. \nFigure 1C shows the model-generated and empirical MEG time series during noun and noise trials for an exemplar subject. \n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "8. Simulate models for longer (model was fitted with 500 ms of data, we will simulate 1500 ms!)\n -------------------------------------------------------------------------\nWe are interested in capturing changes in beta power between verb and noise trials observed from 700-1200 ms\nCreate longer empty array with same shape and fill with the first 500 ms\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sim_1500_verb = np.zeros((verb_meg.shape[0], 1500))\nsim_1500_verb[:,:verb_meg.shape[1]] = verb_meg*1.0e13\nnode_size = sc.shape[0]\noutput_size = sim_1500_verb.shape[0]\nbatch_size = 250\nstep_size = 0.0001\ninput_size = 3\nnum_epoches = 2\ntr = 0.001\nstate_size = 6\nbase_batch_num = 20\ntime_dim = sim_1500_verb.shape[1]\nhidden_size = int(tr/step_size)\ndata_mean = dataloader((sim_1500_verb-sim_1500_verb.mean(0)).T, num_epoches, batch_size)\nverb_F.ts = data_mean\nu = np.zeros((node_size,hidden_size,time_dim))\nu[:,:,100:140]= 5000\noutput_test = verb_F.test(base_batch_num, u=u)\n#extract simulated sensor and source data for noise trials\nsim_source_verb = verb_F.output_sim.P_test\nsim_sensor_verb = verb_F.output_sim.eeg_test\n\n#repeat for noise trials\nsim_1500_noise = np.zeros((noise_meg.shape[0], 1500))\nsim_1500_noise[:,:noise_meg.shape[1]] = noise_meg*1.0e13\nnode_size = sc.shape[0]\noutput_size = sim_1500_noise.shape[0]\nbatch_size = 250\nstep_size = 0.0001\ninput_size = 3\nnum_epoches = 2\ntr = 0.001\nstate_size = 6\nbase_batch_num = 20\ntime_dim = sim_1500_noise.shape[1]\nhidden_size = int(tr/step_size)\ndata_mean = dataloader((sim_1500_noise-sim_1500_noise.mean(0)).T, num_epoches, batch_size)\nnoise_F.ts = data_mean\nu = np.zeros((node_size,hidden_size,time_dim))\nu[:,:,100:140]= 5000\noutput_test = noise_F.test(base_batch_num, u=u)\n#extract simulated sensor and source data for noise trials\nsim_source_noise = noise_F.output_sim.P_test\nsim_sensor_noise = noise_F.output_sim.eeg_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "9. Compare empirical and simulated change in beta power between verb and noise trials for one subject\n -------------------------------------------------------------------------\nWe are replicating figure 1D (Adolescents) for one subject\nWe will load the empirical source data (model was fitted with sensor MEG data) and simulated source from pretrained model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "emp_source_noise = np.load(os.path.join(output_dir, 'emp_noise_source.npy'))\nemp_source_verb = np.load(os.path.join(output_dir, 'emp_verb_source.npy'))\nsim_source_noise = np.load(os.path.join(output_dir, 'sim_noise_source.npy'))\nsim_source_verb = np.load(os.path.join(output_dir, 'sim_verb_source.npy'))\n\n#Compute beta power\n# Sampling parameters\nfs = 1000  # Sampling frequency (Hz)\nnperseg = 512  # Segment length (500 ms)\nnoverlap = 256  # 50% overlap\n# Index of frequency range for beta power corresponding to (13-30 Hz)\nstart_freq = 7\nend_freq = 16\n#We focus on the frontal regions\n# Define frontal ROIs of shen atlas based on mask (subtract 1 for Python indexing)\nfrontal_rois = np.array([2, 7, 10, 17, 18, 24, 25, 26, 28, 30, 31, 33,\n                         37, 38, 42, 50, 56, 59, 61, 62, 65, 66, 68, 71, 77,\n                         78, 83, 91, 92, 94, 96, 98, 99, 100, 101, 102, 103,\n                         108, 110, 113, 117, 125, 126, 129, 132, 133, 135, 137,\n                         140, 142, 150, 158, 161, 172, 178, 180, 182, 183]) - 1\n\n# Separate left and right hemisphere indices\nright_frontal_idx = frontal_rois[frontal_rois < 93]\nleft_frontal_idx = frontal_rois[frontal_rois > 93]\nemp_verb_psd = scipy.signal.welch(emp_source_verb[:, :, 1200:1700], fs=fs, noverlap=noverlap, nperseg=nperseg, detrend='linear')\nemp_noise_psd = scipy.signal.welch(emp_source_noise[:, :, 1200:1700], fs=fs, noverlap=noverlap, nperseg=nperseg, detrend='linear')\nsim_verb_psd = scipy.signal.welch(sim_source_verb[:, 800:1300], fs=fs, noverlap=noverlap, nperseg=nperseg, detrend='linear')\nsim_noise_psd = scipy.signal.welch(sim_source_noise[:, 800:1300], fs=fs, noverlap=noverlap, nperseg=nperseg, detrend='linear')\n#We average beta power across trials \nemp_verb_beta= np.mean(emp_verb_psd[1][:, :, start_freq:end_freq], axis=(2))\nemp_noise_beta= np.mean(emp_noise_psd[1][:, :, start_freq:end_freq], axis=(2))\nsim_verb_beta=np.mean(sim_verb_psd[1][:, start_freq:end_freq], axis=1)\nsim_noise_beta=np.mean(sim_noise_psd[1][:, start_freq:end_freq], axis=1)\nemp_beta_diff = (np.mean(emp_verb_beta, axis=1)) - (np.mean(emp_noise_beta, axis=1))\nsim_beta_diff = (np.array(sim_verb_beta)) - (np.array(sim_noise_beta))\n#We seperate right and left regions to observe ERD in the left and ERS in the right\nright_emp_avg = np.mean(emp_beta_diff[right_frontal_idx])\nleft_emp_avg = np.mean(emp_beta_diff[left_frontal_idx])\nright_sim_avg = np.mean(sim_beta_diff[right_frontal_idx])\nleft_sim_avg = np.mean(sim_beta_diff[left_frontal_idx])\n#Plot beta power difference in left and right frontal regions\nlabels = ['Data', 'Simulated']\nx = np.arange(len(labels))\nwidth = 0.35\nfig, ax = plt.subplots(figsize=(3, 3), dpi=300)\nax.bar(x - width / 2, [left_emp_avg, left_sim_avg], width, label='Left Frontal',\n        capsize=5, color='#6a9ef9', edgecolor='#6a9ef9')\nax.bar(x + width / 2, [right_emp_avg, right_sim_avg], width, label='Right Frontal',\n        capsize=5, color='#e97773', edgecolor='#e97773')\nax.set_ylabel('Verb-Noise Beta Power', fontsize=14)\nax.set_xticks(x)\nax.set_xticklabels(labels)\nplt.axhline(0, color='black', linewidth=1)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Results Description:**\nRemarkably, despite being trained solely on early responses (0\u2013400 ms), the models generalized beyond the fitted time window and domain, predicting beta-band oscillations (13-30 Hz) observed in a later time window during language production (700\u20131200 ms; Fig. 1B) in the frequency domain (Fig. 1D). This is a non-trivial result that highlights the model's capacity to link temporal and spectral features of neural dynamics during the task. For this adolescent subject, models predicted a left-lateralized pattern, with left-right difference in the noun-noise beta power difference. Specifically, lower beta power, relative to noise trials, in the left frontal lobe (ERD) and greater beta power in the right (ERS) was observed. In the paper (Figure 1E) we compare the pattern of beta ERD/S between young children and adolescents and uur simulations captured developmental differences in the degree of lateralization of language production oscillatory patterns in response to speech versus noise (Fig. 1E). \n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}